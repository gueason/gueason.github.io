{"title":"机器学习初级（搬运）","uid":"c8b121ec7894987ab65ba8cb5cccd987","slug":"机器学习初级","date":"2024-07-01T00:00:00.000Z","updated":"2024-08-19T14:22:26.270Z","comments":true,"path":"api/articles/机器学习初级.json","keywords":null,"cover":[],"content":"<h1 id=\"一、绪论\"><a href=\"#一、绪论\" class=\"headerlink\" title=\"一、绪论\"></a>一、绪论</h1><h2 id=\"1-1-Machine-Learning-definition\"><a href=\"#1-1-Machine-Learning-definition\" class=\"headerlink\" title=\"1.1 Machine Learning definition\"></a>1.1 Machine Learning definition</h2><p>Arthur Samuel (1959). Machine Learning: “Field of study that gives computers the ability to learn without being explicitly programmed.”<br>在没有明确设置的情况下，使计算机具有学习能力的研究领域。</p>\n<p>Tom Mitchell (1998) Well-posed Learning Problem: “A computer program is said to learn from experience E with respect to some task T and some performance measure P, if its performance on T, as measured by P, improves with experience E.”<br>字幕翻译：计算机程序从经验E中学习解决某一任务T进行某一性能度量P，通过P测定在T上的表现因经验E而提高。</p>\n<p>DeepL：如果一个计算机程序在某个任务T和某个性能指标P方面的性能随着经验E的增加而提高，那么它就被称为从经验E中学习。</p>\n<h3 id=\"样本-sample-、特征-feature-、标签-label\"><a href=\"#样本-sample-、特征-feature-、标签-label\" class=\"headerlink\" title=\"样本(sample)、特征(feature)、标签(label)\"></a>样本(sample)、特征(feature)、标签(label)</h3><p><strong>样本（Sample）</strong>是用于描述一个事件或一个对象的记录的集合，也可以理解为模型训练和学习的基础数据单元。</p>\n<p><strong>特征（Feature）</strong>是描述一个实例的属性或特点，也可以称为自变量（Independent Variable）或输入变量（Input Variable）。特征构成了机器学习模型的输入部分，用于描述样本或数据点。模型通过学习样本的特征与其对应的标签（或输出）之间的关系来做出预测或分类。</p>\n<p>特征可以是任何类型的数据，包括数字、文本、图像和音频等。根据取值不同，特征可以分为<strong>离散特征</strong>和<strong>连续特征。</strong></p>\n<p><strong>标签（Label）</strong>是指与样本相关联的目标值或预期输出。它代表了我们希望模型从输入数据中学习并预测的结果。</p>\n<p>标签可以是离散的类别值，也可以是连续的数值。</p>\n<p>在分类问题中，标签通常表示样本所属的类别或分类结果。例如，在图像分类任务中，标签可以是图片中物体的类别（如“猫”、“狗”等）。</p>\n<p>在回归问题中，标签是连续的数值，代表了某种度量或预测结果，如房价、股票价格或温度预测等。</p>\n<p><strong>标签为机器学习模型提供了明确的训练目标和方向。</strong></p>\n<p>在监督学习任务中，模型需要通过学习从输入数据中提取特征，并将这些特征映射到正确的标签上。</p>\n<p>标签为模型提供了一个明确的标准，使模型能够评估其预测的准确性，并据此调整其参数和结构，以优化其性能。</p>\n<p>每个样本通常由一组特征（Feature）组成，这些特征可以是数值、文本、图像等各种形式的数据。</p>\n<p>样本可以看作是机器学习模型的输入，用于训练和优化模型。</p>\n<p>具体来说，样本是数据集中的一个元素，用于表示一个独立的数据点或实例。</p>\n<p>样本通常包括一个标签（Label），即与样本对应的预期输出或结果。</p>\n<p>模型通过比较预测结果与样本标签之间的差异，来优化自身的参数和结构，从而提高预测性能。</p>\n<p><strong>举一个例子，假设我们正在构建一个用于识别手写数字的图像分类模型。</strong></p>\n<p>在这个例子中，每一张手写数字的图片都可以看作是一个样本。</p>\n<p>每张图片中的像素值、颜色、纹理等信息都可以提取为特征。</p>\n<p>同时，我们还知道每张图片对应的真实数字（如0-9），这就是样本的标签。</p>\n<h2 id=\"1-2-Supervised-Learning\"><a href=\"#1-2-Supervised-Learning\" class=\"headerlink\" title=\"1.2 Supervised Learning\"></a>1.2 Supervised Learning</h2><p><strong>1.2.1 Definition</strong></p>\n<p>根据已有的数据集，知道输入和输出结果之间的关系。根据这种已知的关系，训练得到一个最优的模型。</p>\n<p>在监督学习中训练数据既有<strong>特征(feature)又有标签(label)</strong>，通过训练，让机器可以自己找到特征和标签之间的联系，在面对只有特征没有标签的数据时，可以判断出标签。</p>\n<p>简单理解：可以把监督学习理解为我们教机器如何做事情。</p>\n<p><img src=\"../img/1334d541cd1944449cfae175fe326d00.png\" alt=\"img\"></p>\n<p><strong>1.2.2 Classification</strong></p>\n<p>监督学习任务主要包括分类和回归两种类型，在监督学习中，数据集中的样本被称为“训练样本”，并且每个样本都有一个输入特征和相应的标签（分类任务）或目标值（回归任务）。</p>\n<p><strong>分类（Classification）：</strong> 在分类任务中，目标是将输入数据分到预定义的类别中。每个类别都有一个唯一的标签。算法在训练阶段通过学习数据的特征和标签之间的关系来构建一个模型。然后，在测试阶段，模型用于预测未见过的数据的类别标签。例如，将电子邮件标记为“垃圾邮件”或“非垃圾邮件”，将图像识别为“猫”或“狗”。</p>\n<p><strong>回归（Regression）：</strong> 在回归任务中，目标是预测连续数值的输出。与分类不同，输出标签在回归任务中是连续的。算法在训练阶段通过学习输入特征和相应的连续输出之间的关系来构建模型。在测试阶段，模型用于预测未见过的数据的输出值。例如，预测房屋的售价、预测销售量等。</p>\n<p><strong>1.2.3 Common Algorithms</strong></p>\n<p>监督学习算法种类众多，有着极其广泛的应用，下面是一些常见的监督学习算法：</p>\n<p><strong>支持向量机（Support Vector Machine，SVM）：</strong>SVM是一种用于二分类和多分类任务的强大算法。它通过找到一个最优的超平面来将不同类别的数据分隔开。SVM在高维空间中表现良好，并且可以应用于线性和非线性分类问题。</p>\n<p><strong>决策树（Decision Trees）：</strong>决策树是一种基于树结构的分类和回归算法。它通过在特征上进行递归的二分决策来进行分类或预测。决策树易于理解和解释，并且对于数据的处理具有良好的适应性。</p>\n<p><strong>逻辑回归（Logistic Regression）：</strong>逻辑回归是一种广泛应用于二分类问题的线性模型。尽管名字中带有”回归”，但它主要用于分类任务。逻辑回归输出预测的概率，并使用逻辑函数将连续输出映射到[0, 1]的范围内。</p>\n<p><strong>K近邻算法（K-Nearest Neighbors，KNN）：</strong>KNN是一种基于实例的学习方法。它根据距离度量来对新样本进行分类或回归预测。KNN使用最接近的K个训练样本的标签来决定新样本的类别。</p>\n<p><strong>1.2.4 Applications</strong></p>\n<p><strong>图像识别：</strong>监督学习在图像识别任务中非常常见。例如，将图像分类为不同的物体、场景或动作，或者进行目标检测，找出图像中特定对象的位置。</p>\n<p><strong>自然语言处理：</strong>在自然语言处理任务中，监督学习用于文本分类、情感分析、机器翻译、命名实体识别等。</p>\n<p><strong>语音识别：</strong>监督学习在语音识别领域被广泛应用，例如将语音转换为文本、说话者识别等。</p>\n<p><strong>医学诊断：</strong>在医学领域，监督学习可以用于疾病诊断、影像分析、药物发现等。</p>\n<h2 id=\"1-3-Unsupervised-Learning\"><a href=\"#1-3-Unsupervised-Learning\" class=\"headerlink\" title=\"1.3 Unsupervised Learning\"></a>1.3 Unsupervised Learning</h2><p><strong>1.3.1 Definition</strong></p>\n<p>我们不知道数据集中数据、特征之间的关系，而是要根据聚类或一定的模型得到数据之间的关系。</p>\n<p>在无监督学习中数据只有特征(feature)无标签(label)，是一种机器学习的训练方式，它本质上是一个统计手段，在没有标签的数据里可以发现潜在的一些结构的一种训练方式。</p>\n<p>简单理解：比起监督学习，无监督学习更像是自学，让机器学会自己做事情。</p>\n<p><strong>1.3.2 Classification</strong></p>\n<p><strong>聚类（Clustering）：</strong>聚类是将数据样本分成相似的组别或簇的过程。它通过计算样本之间的相似性度量来将相似的样本聚集在一起。聚类是无监督学习中最常见的任务之一，常用于数据分析、市场细分、图像分割等。</p>\n<p><strong>降维（Dimensionality Reduction）：</strong>降维是将高维数据转换为低维表示的过程，同时尽可能地保留数据的特征。降维技术可以减少数据的复杂性、去除冗余信息，并可用于可视化数据、特征提取等。常见的降维方法有主成分分析（PCA）和t-SNE等。</p>\n<p><strong>关联规则挖掘（Association Rule Mining）：</strong>关联规则挖掘用于发现数据集中项之间的关联和频繁项集。这些规则描述了数据集中不同项之间的关联性，通常在市场篮子分析、购物推荐等方面应用广泛。</p>\n<p><strong>异常检测（Anomaly Detection）：</strong>异常检测用于识别与大多数样本不同的罕见或异常数据点。它在检测异常事件、欺诈检测、故障检测等领域有着重要的应用。</p>\n<p><strong>1.3.3 Common Algorithms</strong></p>\n<p><strong>K均值聚类（K-Means Clustering）：</strong>K均值聚类是一种常用的聚类算法，它将数据样本分成K个簇，使得每个样本与所属簇中心的距离最小化。</p>\n<p><strong>主成分分析（Principal Component Analysis，PCA）：</strong>PCA是一种常用的降维算法，它通过线性变换将高维数据投影到低维空间，以保留最重要的特征。</p>\n<p><strong>关联规则挖掘（Association Rule Mining）：</strong>关联规则挖掘是一种发现数据集中项之间关联性的方法，它常用于市场篮子分析、购物推荐等领域。</p>\n<p><strong>异常检测（Anomaly Detection）：</strong>异常检测算法用于识别与大多数样本不同的罕见或异常数据点。常见的方法包括基于统计的方法、基于聚类的方法和基于生成模型的方法等。</p>\n<p><strong>1.3.4 Applications</strong></p>\n<p>无监督学习在数据挖掘、模式识别、特征学习等应用场景发挥着重要作用。通过无监督学习，我们可以从未标记的数据中获得有用的信息和洞察力，为其他任务提供有益的预处理步骤，并且有助于更好地理解和利用数据。：</p>\n<p><strong>聚类与分组：</strong>无监督学习中的聚类算法可以帮助将数据样本分成相似的组别或簇，例如在市场细分中将顾客分成不同的群体、在图像分割中将图像区域分割成不同的物体等。</p>\n<p><strong>特征学习与降维：</strong>无监督学习的降维算法如PCA和t-SNE可以用于特征学习和可视化高维数据，例如在图像、音频和自然语言处理中，以及用于数据压缩和可视化。</p>\n<p><strong>异常检测：</strong>无监督学习中的异常检测算法可用于发现与大多数数据样本不同的罕见或异常数据点。这在欺诈检测、故障检测和异常事件监测等场景中具有重要应用。</p>\n<p><strong>关联规则挖掘：</strong>无监督学习的关联规则挖掘算法可用于发现数据集中项之间的关联性，常应用于市场篮子分析、购物推荐等领域。</p>\n<h2 id=\"1-4-Semi-supervised-Learning\"><a href=\"#1-4-Semi-supervised-Learning\" class=\"headerlink\" title=\"1.4 Semi-supervised Learning\"></a>1.4 Semi-supervised Learning</h2><p><strong>1.4.1Definition</strong></p>\n<p>半监督学习的目标是利用同时包含有标签和无标签的数据来构建一个模型，使得模型能够在测试阶段更好地泛化到新的、未见过的数据。</p>\n<p>半监督学习介于监督学习和无监督学习之间。在半监督学习中，训练数据同时包含有标签的数据和无标签的数据。</p>\n<p>与监督学习不同的是，半监督学习的训练数据中只有一小部分样本是带有标签的，而大部分样本是没有标签的。通常情况下，获取带有标签的数据可能会比较昂贵或耗费大量的时间，而采集无标签的数据则相对容易和便宜。</p>\n<p><strong>在半监督学习中，无标签的数据可以起到两个重要作用：</strong></p>\n<p>利用未标记数据的信息：未标记数据可能包含对数据分布、结构和隐含特征的有用信息，这些信息可以帮助模型更好地进行泛化。</p>\n<p>利用标记数据的传播效应：通过利用标记数据与无标签数据之间的数据分布相似性，可以通过传播标签信息到无标签样本，进而增强模型的性能。</p>\n<p><img src=\"../img/6d7c68a3c8124ec7b9a2bd9d6ace1336.png\" alt=\"img\"></p>\n<p><strong>1.4.2 Classification</strong></p>\n<p><strong>半监督分类（Semi-supervised Classification）：</strong>在半监督分类中，训练数据中同时包含带有标签的样本和无标签的样本。模型的目标是利用这些标签信息和无标签数据的分布信息来提高分类性能。半监督分类算法可以在分类任务中利用未标记数据来扩展有标签数据集，从而提高模型的准确性。</p>\n<p><strong>半监督回归（Semi-supervised Regression）：</strong>半监督回归任务与半监督分类类似，但应用于回归问题。模型通过有标签的数据和无标签数据进行训练，以提高对未标记数据的回归预测准确性。</p>\n<p><strong>半监督聚类（Semi-supervised Clustering）：</strong>半监督聚类算法将有标签数据和无标签数据同时用于聚类任务。它们可以通过结合数据的相似性信息和标签信息，来更好地识别潜在的簇结构。</p>\n<p><strong>半监督异常检测（Semi-supervised Anomaly Detection）：</strong>半监督异常检测任务旨在从同时包含正常样本和异常样本的数据中，利用有限的标签信息来检测异常。这在异常样本较少的情况下特别有用。</p>\n<p><strong>生成对抗网络（GANs）中的半监督学习：</strong>GANs可以被用于实现半监督学习。在这种情况下，生成器和判别器网络可以使用有标签和无标签的样本，以提高生成模型的性能。</p>\n<p><strong>1.4.3 Common Algorithms</strong></p>\n<p>半监督学习算法可以在不同的问题和数据集上发挥作用。选择合适的半监督学习算法取决于问题的特性、可用的有标签和无标签数据量，以及算法的性能和复杂度要求。半监督学习在处理数据有限或数据标记成本高昂的场景下具有重要的应用价值。以下是一些常见的半监督学习算法：</p>\n<p><strong>自训练（Self-Training）：</strong>自训练是一种简单的半监督学习方法。它通过使用有标签数据训练一个初始模型，然后使用该模型对未标记数据进行预测，并将置信度较高的预测结果作为伪标签，将未标记数据添加到有标签数据中，然后重新训练模型。</p>\n<p><strong>协作训练（Co-Training）：</strong>协作训练是一种使用多个视图或特征的半监督学习方法。它通过将数据划分为两个或多个视图，并在每个视图上独立训练模型。然后，模型之间相互交互并使用对方的预测结果来增强训练。</p>\n<p><strong>半监督支持向量机（Semi-Supervised Support Vector Machines）：</strong>半监督支持向量机是基于支持向量机的半监督学习方法。它利用有标签数据和未标记数据之间的关系来学习一个更好的分类器。</p>\n<p><strong>生成式半监督学习（Generative Semi-Supervised Learning）：</strong>这类方法尝试使用生成模型来建模数据的分布，并利用有标签和无标签数据共同训练生成模型，以提高对未标记数据的预测。</p>\n<p><strong>半监督深度学习：</strong>近年来，许多深度学习方法已经扩展到半监督学习。这些方法通过在深度神经网络中引入半监督性质，如半监督自编码器（Semi-Supervised Autoencoders）等，来利用未标记数据的信息。</p>\n<p><strong>图半监督学习（Graph-based Semi-Supervised Learning）：</strong>图半监督学习方法利用数据样本之间的关系来辅助半监督学习。这些方法通常利用图模型或图卷积神经网络（GCN）来利用数据的拓扑结构。</p>\n<p><strong>1.4.4 Applications</strong></p>\n<p>半监督学习在许多实际应用场景中具有重要的应用价值，尤其在数据有限或数据标记成本高昂的情况下。以下是一些半监督学习的应用场景：</p>\n<p><strong>自然语言处理：</strong>在自然语言处理任务中，很多时候获取大规模的标记数据是非常昂贵和耗时的。半监督学习可以利用少量有标签的文本数据和大量未标签的文本数据来提高文本分类、情感分析、命名实体识别等任务的性能。</p>\n<p><strong>图像识别和计算机视觉：</strong>在图像识别和计算机视觉领域，获取大规模的标记图像数据也可能是困难的。半监督学习可以在少量有标签图像和大量未标签图像上进行训练，以提高图像分类、目标检测等任务的准确性。</p>\n<p><strong>数据聚类：</strong>在聚类任务中，半监督学习可以将有标签和未标签数据结合起来进行聚类，从而提高聚类结果的准确性和稳定性。</p>\n<p><strong>医学图像和诊断：</strong>在医学图像分析和诊断中，获取大量标记的医学图像数据可能是困难的。半监督学习可以在少量有标签医学图像和大量未标签医学图像上进行训练，提高医学图像分割、病变检测等任务的性能。</p>\n<p><strong>机器人控制：</strong>在机器人控制领域，半监督学习可以帮助机器人在未知环境中进行自主决策和学习，从而提高其任务执行能力。</p>\n<p><strong>图像生成和数据增强：</strong>在生成式模型中，半监督学习可以结合有标签和未标签数据来训练模型，以提高生成模型的质量和多样性。</p>\n<h2 id=\"1-5-Reinforcement-Learning\"><a href=\"#1-5-Reinforcement-Learning\" class=\"headerlink\" title=\"1.5 Reinforcement Learning\"></a>1.5 Reinforcement Learning</h2><p><strong>1.5.1Definition</strong></p>\n<p>强化学习是让一个智能体（agent）在环境中通过尝试和错误来学习行为策略。智能体通过与环境进行交互，根据奖励信号来调整其行为策略，以达到最大化累积奖励的目标。</p>\n<p>在强化学习中，智能体不需要明确地告诉如何执行任务，而是通过尝试和错误的方式进行学习。当智能体在环境中采取某个动作时，环境会返回一个奖励信号，表示该动作的好坏程度。智能体的目标是通过与环境交互，学习到一种最优策略，使其在长期累积的奖励最大化。<br><img src=\"../img/83cfc7cc400440b4a3929f2377eb066f.png\" alt=\"img\"></p>\n<p><strong>1.5.2 Classification</strong></p>\n<p><strong>基于值的强化学习（Value-Based Reinforcement Learning）：</strong>基于值的强化学习方法旨在学习价值函数，即给定状态或状态-动作对的值，代表了智能体在该状态或状态-动作对上能够获得的累积奖励的估计值。这些方法通常通过使用贝尔曼方程或其变种来更新价值函数，并使用它来选择动作。</p>\n<p><strong>基于策略的强化学习（Policy-Based Reinforcement Learning）：</strong>基于策略的强化学习方法直接学习策略函数，即将状态映射到动作的映射。策略可以是确定性的（对于每个状态只输出一个动作）或是概率性的（对于每个状态输出动作的概率分布）。这些方法通常通过梯度上升方法来更新策略参数，以最大化累积奖励。</p>\n<p><strong>基于模型的强化学习（Model-Based Reinforcement Learning）：</strong>基于模型的强化学习方法学习环境的模型，即从状态和动作预测下一个状态和奖励。然后，它可以使用学到的模型进行规划和决策，而无需真实地与环境进行交互。这样可以提高样本效率和规划效率。</p>\n<p><strong>深度强化学习（Deep Reinforcement Learning）：</strong>深度强化学习将深度神经网络与强化学习相结合。它通常使用深度神经网络来近似值函数或策略函数。深度强化学习在处理高维状态空间和动作空间的任务时表现出色。</p>\n<p><strong>多智能体强化学习（Multi-Agent Reinforcement Learning）：</strong>多智能体强化学习研究多个智能体在相互作用环境中的学习问题。在这种情况下，每个智能体的策略和动作会影响其他智能体的状态和奖励，因此学习变得更加复杂。</p>\n<p><strong>1.5.3 Common Algorithms</strong></p>\n<p><strong>Q-Learning：</strong>Q-Learning是一种基于值的强化学习算法。它通过学习一个值函数（Q函数）来表示在给定状态下采取某个动作的累积奖励。Q-Learning使用贝尔曼方程更新Q值，并使用贪心策略来选择动作。</p>\n<p><strong>SARSA：</strong>SARSA是另一种基于值的强化学习算法。它与Q-Learning类似，但不同之处在于它在学习和决策阶段都使用当前策略的动作来更新Q值。</p>\n<p><strong>DQN（Deep Q Network）：</strong>DQN是一种深度强化学习算法，结合了深度神经网络和Q-Learning。它使用深度神经网络来近似Q函数，通过经验回放和目标网络来稳定训练。</p>\n<p><strong>A3C（Asynchronous Advantage Actor-Critic）：</strong>A3C是一种基于策略的强化学习算法，它结合了Actor-Critic方法和异步训练。A3C使用多个智能体并行地训练，以提高样本效率。</p>\n<p><strong>PPO（Proximal Policy Optimization）：</strong>PPO是一种基于策略的强化学习算法，它通过限制更新幅度来稳定训练。PPO在深度强化学习中表现出色，并被广泛应用于各种任务。</p>\n<p><strong>TRPO（Trust Region Policy Optimization）：</strong>TRPO是另一种基于策略的强化学习算法，它使用限制步长的方法来保证更新策略时不会使性能变差。</p>\n<p><strong>1.5.4 Applications</strong></p>\n<p>强化学习在许多实际应用场景中具有广泛的应用，尤其是那些需要自主决策和学习的任务。强化学习能够使智能体从与环境的交互中学习，并根据学到的知识做出适当的决策，以达到预定的目标或最大化累积奖励。由于强化学习的自主学习和决策特性，它在许多自主系统和智能系统中都有重要的应用潜力。以下是一些强化学习的应用场景：</p>\n<p><strong>自动驾驶：</strong>强化学习可以应用于自动驾驶领域，使车辆能够根据环境和交通状况做出决策，例如规划路径、避免障碍物和遵守交通规则。</p>\n<p><strong>机器人控制：</strong>强化学习可以帮助机器人在未知环境中进行自主探索和学习，以完成复杂的任务，例如导航、抓取物体和人机交互。</p>\n<p><strong>游戏：</strong>强化学习在游戏玩法中有广泛的应用。例如，使用强化学习训练智能体来玩电子游戏、围棋、扑克等，使其能够与人类玩家媲美甚至超越。</p>\n<p><strong>医疗治疗：</strong>强化学习可以在医疗领域中应用于个性化治疗和药物治疗决策，根据患者的情况和病情做出合适的治疗计划。</p>\n<p><strong>语音识别和自然语言处理：</strong>强化学习可以应用于语音识别和自然语言处理任务，使智能体能够更好地理解和生成自然语言。</p>\n<hr>\n<h1 id=\"二、单变量线性回归\"><a href=\"#二、单变量线性回归\" class=\"headerlink\" title=\"二、单变量线性回归\"></a>二、单变量线性回归</h1><h2 id=\"2-1-参数-Parameter\"><a href=\"#2-1-参数-Parameter\" class=\"headerlink\" title=\"2.1 参数(Parameter)\"></a>2.1 参数(Parameter)</h2><p><strong>模型参数：</strong>模型内部的配置变量，可以通过数据估计（学习）模型参数的值<br><strong>超参数：</strong>模型的外部配置变量，需要手动设置，好的超参数可以进一步提高模型的性能</p>\n<p><strong>模型参数的特点：</strong><br>1.进行模型预测时需要模型参数；<br>2.可定义模型功能；<br>3.可使用数据估计/学习得到；<br>4.一般不用手动设置；<br>5.作为学习模型的一部分保留<br>比如：神经网络中的权重，线性回归中的系数</p>\n<p><strong>超参数的特点：</strong><br>1.常应用于估计模型参数的过程中，在开始学习之前就要设置好；训练过程不影响超参数<br>2.通常要手动设置<br>3.通常不能从数据中估计（学习）得到，一般需要通过经验设定；<br>4.定义关于模型的更高层次的概念，如复杂性或学习能力<br>比如：学习率，K邻域中的K</p>\n<h2 id=\"2-2-训练集（train-set）、验证集（validation-set）、验证集（validation-set）\"><a href=\"#2-2-训练集（train-set）、验证集（validation-set）、验证集（validation-set）\" class=\"headerlink\" title=\"2.2 训练集（train set）、验证集（validation set）、验证集（validation set）\"></a>2.2 训练集（train set）、验证集（validation set）、验证集（validation set）</h2><p><strong>训练集（train set）</strong> —— 用于训练模型（拟合参数）：即模型拟合的数据样本集合，如通过训练拟合一些参数来建立一个分类器。</p>\n<p><strong>验证集（validation set）</strong>—— 用于确定网络结构或者控制模型复杂程度的超参数（拟合超参数）：是模型训练过程中单独留出的样本集，它可以用于调整模型的超参数和用于对模型的能力进行初步评估。 通常用来在模型迭代训练时，用以验证当前模型泛化能力（准确率，召回率等），防止过你话的现象出现，以决定如何调整超参数。具体原理参照本文的二（三）。</p>\n<p><strong>测试集（test set）</strong> —— 用来评估模最终模型的性能如何（评价模型好坏）：测试集没有参于训练，主要是测试训练好的模型的准确能力等，但不能作为调参、选择特征等算法相关的选择的依据。说白了就只用于评价模型好坏的一个数据集。</p>\n<p>基于数据集是否参与了训练过程，可通过下图来理解，即测试集完全没参与训练，它只是用于测试，评估模型到底性能如何</p>\n<p><img src=\"../img/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAbW9veXVhbg==,size_20,color_FFFFFF,t_70,g_se,x_16.png\" alt=\"img\" style=\"zoom:67%;\" /></p>\n<p><img src=\"../img/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAbW9veXVhbg==,size_20,color_FFFFFF,t_70,g_se,x_16-172164284905710.png\" alt=\"img\" style=\"zoom:67%;\" /></p>\n<p>在机器学习的上下文中，超参数是在开始学习过程之前设置值的参数，而不是通过训练得到的参数数据。通常情况下，需要对超参数进行优化，给学习机选择一组最优超参数，以提高学习的性能和效果。</p>\n<p>如果数据集仅仅分为训练集和测试集，那么通过修改一些超参数（不能通过学习来自动调整的参数）来降低误差，但是这种方法在实际中的应用效果却并没有想象的那么好。这是因为超参数都是基于测试集来调整的，就相当于把测试集当成了训练超参数的数据。这样对于新的数据效果不一定会更好。</p>\n<p>于是就想出一种解决办法，即保留一个数据集作为验证集，在这些步骤做完之后再进行最终的验证。</p>\n<p><img src=\"../img/image-20240804225622237.png\" alt=\"image-20240804225622237\"></p>\n<h2 id=\"2-3-交叉验证（Cross-Validation）\"><a href=\"#2-3-交叉验证（Cross-Validation）\" class=\"headerlink\" title=\"2.3 交叉验证（Cross-Validation）\"></a>2.3 交叉验证（Cross-Validation）</h2><p>     交叉验证是在机器学习建立模型和验证模型参数时常用的办法，一般被用于评估一个机器学习模型的表现。更多的情况下，我们也用交叉验证来进行模型选择(model selection)。</p>\n<p>     交叉验证把得到的样本数据进行切分，组合为不同的训练集和测试集，用训练集来训练模型，用测试集来评估模型预测的好坏。在此基础上可以得到多组不同的训练集和测试集，某次训练集中的某样本在下次可能成为测试集中的样本。</p>\n<p>     交叉验证用在数据不是很充足的时候。如果数据样本量小于一万条，我们就会采用交叉验证来训练优化选择模型。如果样本大于一万条的话，我们一般随机的把数据分成三份，一份为训练集（Training Set），一份为验证集（Validation Set），最后一份为测试集（Test Set）。用训练集来训练模型，用验证集来评估模型预测的好坏和选择模型及其对应的参数。把最终得到的模型再用于测试集，最终决定使用哪个模型以及对应参数。</p>\n<p><strong>留出法 （holdout cross validation）</strong></p>\n<p>随机的将样本数据分为两部分（比如： 70%的训练集，30%的测试集），然后用训练集来训练模型，在测试集上验证模型及参数。接着，我们再把样本打乱，重新选择训练集和测试集，继续训练数据和检验模型。最后选择损失函数评估最优的模型和参数。</p>\n<p><strong>k 折交叉验证（k-fold cross validation</strong>）</p>\n<p>k 折交叉验证通过对 k 个不同分组训练的结果进行平均来减少方差， 因此模型的性能对数据的划分就不那么敏感。</p>\n<ul>\n<li>第一步，不重复抽样将原始数据随机分为 k 份。</li>\n<li>第二步，每一次挑选其中 1 份作为测试集，剩余 k-1 份作为训练集用于模型训练。</li>\n<li>第三步，重复第二步 k 次，这样每个子集都有一次机会作为测试集，其余机会作为训练集。在每个训练集上训练后得到一个模型，用这个模型在相应的测试集上测试，计算并保存模型的评估指标，</li>\n<li>第四步，计算 k 组测试结果的平均值作为模型精度的估计，并作为当前 k 折交叉验证下模型的性能指标。<br>k 一般取 10， 数据量小的时候，k 可以设大一点，这样训练集占整体比例就比较大，不过同时训练的模型个数也增多。 数据量大的时候，k 可以设小一点。</li>\n</ul>\n<p><img src=\"../img/d867ce333dbd30647e59d7c4771e7d1f.png\" alt=\"img\" style=\"zoom: 50%;\" /></p>\n<p><img src=\"../img/v2-7f165ecd9559047847a04342df538ea0_b.jpg\" alt=\"img\"></p>\n<p><strong>留一法（Leave one out cross validation）</strong></p>\n<p>当 k＝m 即样本总数时， 每次的测试集都只有一个样本，要进行 m 次训练和预测。</p>\n<p>这个方法用于训练的数据只比整体数据集少了一个样本，因此最接近原始样本的分布。 但是训练复杂度增加了，因为模型的数量与原始数据样本数量相同。 一般在数据缺乏时使用。 样本数很多的话，这种方法开销很大。</p>\n<p><strong>Bootstrap</strong></p>\n<ol>\n<li>数据假设要分成10组，则先设置一个采样比例，比如采样比例70%。则10组数据是每次从原始数据集中随机采样总数70%的数据构成训练集1，没有选中的样本作为测试集1；然后把数据放回，再随机采样总数70%的数据构成训练集2，没选中的作为测试集2……以此类推，放回式采样10组。</li>\n<li>训练生成10个模型</li>\n<li>计算平均测试误差来评估当前参数下的模型性能</li>\n</ol>\n<h2 id=\"2-4-损失函数-代价函数（Loss-Cost-Function）\"><a href=\"#2-4-损失函数-代价函数（Loss-Cost-Function）\" class=\"headerlink\" title=\"2.4 损失函数/代价函数（Loss/Cost Function）\"></a>2.4 损失函数/代价函数（Loss/Cost Function）</h2><p>在机器学习中，损失函数是代价函数的一部分，而代价函数则是目标函数的一种类型。</p>\n<p><strong>损失函数(Loss Function)：</strong> 用于定义单个训练样本与真实值之间的误差，也就是就算一个样本的误差，比如我们想要分类，就是预测的类别和实际类别的区别，是一个样本的哦，用L表示。<br><strong>代价函数(Cost Function)：</strong> 用于定义单个批次/整个训练集样本与真实值之间的误差，也就是所有样本的误差的总和的平均，也就是损失函数的总和的平均，有没有这个平均其实不会影响最后的参数的求解结果。<br><strong>目标函数(Objective Function)：</strong> 泛指任意可以被优化的函数。</p>\n<p>在机器学习中，我们想让预测值无限接近于真实值，所以需要将差值降到最低（<strong>在这个过程中就需要引入损失函数</strong>）。而在此过程中损失函数的选择是十分关键的，在具体的项目中，有些损失函数计算的差值梯度下降的快，而有些下降的慢，所以<strong>选择合适的损失函数</strong>也是十分关键的。</p>\n<p>每一个样本经过模型后会得到一个预测值，然后得到的预测值和真实值的差值就成为损失（当然损失值越小证明模型越是成功），我们知道有许多不同种类的损失函数，这些函数本质上就是计算预测值和真实值的差距的一类型函数，然后经过库（如pytorch，tensorflow等）的封装形成了有具体名字的函数。</p>\n<p>输入的feature（或称为x）需要通过模型（model）预测出y，此过程称为<strong>向前传播（forward pass）</strong>，而要将预测与真实值的差值减小需要更新模型中的参数，这个过程称为<strong>向后传播（backward pass）</strong>，其中我们损失函数（lossfunction）就基于这两种传播之间，起到一种有点像承上启下的作用，承上指：接収模型的预测值，启下指：计算预测值和真实值的差值，为下面反向传播提供输入数据。</p>\n<h3 id=\"2-4-1回归损失-Regression-Loss\"><a href=\"#2-4-1回归损失-Regression-Loss\" class=\"headerlink\" title=\"2.4.1回归损失(Regression Loss)\"></a>2.4.1回归损失(Regression Loss)</h3><h4 id=\"L1-Loss\"><a href=\"#L1-Loss\" class=\"headerlink\" title=\"L1 Loss\"></a>L1 Loss</h4><p>也称Mean Absolute Error，即平均绝对误差(MAE)，计算预测值与真实值的差的绝对值，衡量预测值与真实值之间距离的平均误差幅度，范围为0到正无穷。</p>\n<p><img src=\"../img/19a9c5ff91784a15bae40eb72b8cb8bb.png\" alt=\"在这里插入图片描述\" style=\"zoom: 80%;\" /></p>\n<ul>\n<li><strong>Hypotheis:</strong></li>\n</ul>\n<p><img src=\"../img/image-20240725120102110.png\" alt=\"image-20240725120102110\" style=\"zoom: 80%;\" /></p>\n<ul>\n<li><p><strong>Parameters:</strong></p>\n<p>​                                                                          θ<em>0,</em>θ1</p>\n</li>\n</ul>\n<ul>\n<li><strong>Cost function:</strong></li>\n</ul>\n<p><img src=\"../img/image-20240725153237351.png\" alt=\"image-20240725153237351\" style=\"zoom:67%;\" /></p>\n<ul>\n<li><strong>Goal:</strong></li>\n</ul>\n<p><img src=\"../img/image-20240725153412262.png\" alt=\"image-20240725153412262\" style=\"zoom: 80%;\" /></p>\n<p>优点：</p>\n<p>L1损失函数对离群点（Outliers）或者异常值更具有鲁棒性。</p>\n<p>缺点：</p>\n<p>在零处不可导，求解效率低，收敛速度慢；<br>梯度始终相同，即使很小的损失值，梯度也很大，这样不利于模型的收敛。针对它的收敛问题，一般的解决办法是在优化算法中使用变化的学习率，在损失接近最小值时降低学习率。</p>\n<h4 id=\"L2-Loss\"><a href=\"#L2-Loss\" class=\"headerlink\" title=\"L2 Loss\"></a>L2 Loss</h4><p>也称为Mean Squred Error，即均方差(MSE)，计算的是预测值与真实值之间距离的平方和，范围同为0到正无穷。</p>\n<p><img src=\"../img/f4892cce7a3e4284b65f9287d3cda955.png\" alt=\"在这里插入图片描述\"></p>\n<p>优点：</p>\n<p>收敛速度快，能够对梯度给予合适的惩罚权重，而不是“一视同仁”，使梯度更新的方向可以更加精确。<br>缺点：</p>\n<p>对异常值十分敏感，梯度更新的方向很容易受离群点所主导，不具备鲁棒性。</p>\n<h3 id=\"2-4-2分类损失-Classification-Loss\"><a href=\"#2-4-2分类损失-Classification-Loss\" class=\"headerlink\" title=\"2.4.2分类损失(Classification Loss)\"></a>2.4.2分类损失(Classification Loss)</h3><p><strong>Entropy</strong></p>\n<p>熵（信息熵），它可以很好地描述事件的不确定性，衡量的是得到的信息量的期望。同时也反映了在给定概率分布p中样本值的平均信息量的条件下，它的概率分布有多不可预测。<strong>一个事件的不确定性就越大，其信息量越大，它的信息熵就越高。</strong></p>\n<p>交叉熵损失（Cross-entropy loss）衡量了模型预测结果与实际结果之间的差距，是优化模型参数的关键指标之一。交叉熵损失的公式如下： </p>\n<p><img src=\"../img/1219951287c54e6dad0ab18f8d0acc51.png#pic_center\" alt=\"在这里插入图片描述\" style=\"zoom: 67%;\" /></p>\n<p><strong>K-L Divergence</strong><br>KL散度。对于交叉熵损失，除了我们在这里使用预测概率的对数（log(q(i))）外，它看起来与上面熵的方程非常相似。 如果我们的预测是完美的，那就是预测分布等于真实分布，此时交叉熵就等于熵。 但是，如果分布不同，则交叉熵将比熵大一些位数。交叉熵超过熵的量称为相对熵，或更普遍地称为库尔贝克-莱布里埃发散度（KL Divergence）。总结如下：</p>\n<p><img src=\"../img/image-20240725103034599.png\" alt=\"image-20240725103034599\" style=\"zoom: 67%;\" /></p>\n<h2 id=\"2-5-梯度下降-Gradient-Descent\"><a href=\"#2-5-梯度下降-Gradient-Descent\" class=\"headerlink\" title=\"2.5 梯度下降(Gradient Descent)\"></a>2.5 梯度下降(Gradient Descent)</h2><p>梯度下降通过不断迭代计算函数的梯度，判断该点的某一方向和目标之间的距离，最终求得最小的损失函数和相关参数，为建立线性模型提供支持。</p>\n<p>梯度下降是一种广泛用于求解线性和非线性模型最优解的迭代算法，它的中心思想在于通过迭代次数的递增，调整使得损失函数最小化的权重。</p>\n<p>它的作用是用于优化一个目标函数，如果要最小化一个损失函数，使用的就是梯度下降法，如果要最大化一个效用函数，使用的是梯度上升法。</p>\n<p><strong>作用：</strong></p>\n<ol>\n<li>梯度下降梯度下降的目的就是求函数的极小值点，最小化损失函数。</li>\n</ol>\n<ol>\n<li>损失函数就是一个自变量为算法的参数，函数值为误差值的函数。所以梯度下降就是找让误差值最小时候算法取的参数。</li>\n</ol>\n<p><strong>找到 J（θ）的最小值：</strong></p>\n<p><img src=\"../img/image-20240804231112866.png\" alt=\"image-20240804231112866\"></p>\n<p>J(θ)的真正图形类似是一个凸函数，只有一个全局最优解，所以不必担心像上图一样找到局部最优解</p>\n<p><img src=\"../img/640-17219665559518_1.jpg\" alt=\"640-17219665559518_1\" style=\"zoom:80%;\" /></p>\n<p><strong>思想：</strong></p>\n<p>先任取点（x0,f(x0))，求f(x)在该点x0的导数f’(x0),在用x0减去导数值f’(x0),计算所得就是新的点x1,然后再用x1减去f’(x1)得x2…。</p>\n<p>以此类推，循环多次，改变x的值使得导数的绝对值变小，无限接近极小值点。</p>\n<p>当导数小于0时候，让目前x值大一点点，再看它导数值。</p>\n<p>当导数大于0时候，让目前x值减小一点点，再看它导数值。</p>\n<p>当导数接近0时候，就得到想要的自变量x了。也就是说找到这个算法最佳参数，使得拟合曲线与真实值误差最小。</p>\n<p>官方点讲大概意思就是：<strong>梯度下降就是找让误差值最小时的算法取的参数</strong></p>\n<p><img src=\"../img/640-17219661334885.jpg\" alt=\"640\" style=\"zoom:67%;\" /></p>\n<p>损失函数的梯度（即偏导数）为</p>\n<p><img src=\"../img/0737d9a2f4b462fba3d5f674ba9a2de8.png\" alt=\"img\"></p>\n<p>按参数 θ 的梯度负方向，来更新θ，即梯度下降算法为</p>\n<p><strong>repeat until convergence {</strong></p>\n<p><img src=\"../img/image-20240726112120128.png\" alt=\"image-20240726112120128\" style=\"zoom:50%;\" /></p>\n<p><strong>}</strong></p>\n<p><strong>α在梯度下降算法中被称作为学习率或者步长，a的大小，如果a太小，则迭代很多次才找到最优解，若a太大，可能跳过最优解。</strong></p>\n<p><img src=\"../img/image-20240804231058340.png\" alt=\"image-20240804231058340\"></p>\n<p>另外，在不断迭代的过程中，梯度值会不断变小，所以θ1的变化速度也会越来越慢，所以不需要使速率a的值越来越小。它得到的是一个全局最优解，但是每迭代一步，都要用到训练集所有的数据，所以在下图的梯度下降过程中可以看到，它是一个近乎直线的下降过程，直接前往最低点。</p>\n<p><img src=\"../img/640-172198094302612.jpg\" alt=\"640-172198094302612\" style=\"zoom:67%;\" /></p>\n<p>当梯度下降到一定数值后，每次迭代的变化很小，这时可以设定一个阈值，只要变化小鱼该阈值，就停止迭代，而得到的结果也近似于最优解。</p>\n<p><img src=\"../img/image-20240804231044534.png\" alt=\"image-20240804231044534\"></p>\n<p><strong>算法求解过程：</strong></p>\n<p>1）确定当前位置的损失函数的梯度，对于θi,其梯度表达式如下：</p>\n<p><img src=\"../img/image-20240804225858761.png\" alt=\"image-20240804225858761\" style=\"zoom:50%;\" /></p>\n<p>2）用步长乘以损失函数的梯度，得到当前位置下降的距离</p>\n<p>3）确定是否所有的θi,梯度下降的距离都小于ε，如果小于ε则算法终止，当前所有的θi(i=0,1,…n)即为最终结果。否则进入步骤4</p>\n<p>4）更新所有的θ，对于θi，其更新表达式如下。更新完毕后继续转入步骤1.</p>\n<p><img src=\"../img/image-20240804225942993.png\" alt=\"image-20240804225942993\" style=\"zoom: 50%;\" /></p>\n<p>注意：</p>\n<ol>\n<li><p>更新方程时需要同时更新θ</p>\n</li>\n<li><p>先同时计算右边部分，然后同时更新θ</p>\n</li>\n</ol>\n<p><strong>下面用线性回归的例子来具体描述梯度下降</strong></p>\n<p>假设我们的样本是</p>\n<p><img src=\"../img/image-20240804230010692.png\" alt=\"image-20240804230010692\"></p>\n<p>损失函数如前面先决条件所述：</p>\n<p><img src=\"../img/image-20240804230033068.png\" alt=\"image-20240804230033068\" style=\"zoom:50%;\" /></p>\n<p>则在算法过程步骤1中对于θi 的偏导数计算如下：</p>\n<p>!<img src=\"../img/image-20240804230049844.png\" alt=\"image-20240804230049844\"></p>\n<p>由于样本中没有x0上式中令所有的xj0为1.</p>\n<p>步骤4中θi的更新表达式如下：</p>\n<p><img src=\"../img/image-20240804230104327.png\" alt=\"image-20240804230104327\" style=\"zoom: 50%;\" /></p>\n<hr>\n<h1 id=\"三、多变量线性回归-Linear-Regression-with-Multiple-Variables\"><a href=\"#三、多变量线性回归-Linear-Regression-with-Multiple-Variables\" class=\"headerlink\" title=\"三、多变量线性回归(Linear Regression with Multiple Variables)\"></a>三、多变量线性回归(Linear Regression with Multiple Variables)</h1><h2 id=\"3-1-向量化（vectorization）\"><a href=\"#3-1-向量化（vectorization）\" class=\"headerlink\" title=\"3.1 向量化（vectorization）\"></a>3.1 向量化（vectorization）</h2><p>向量化就是非常简单的去除for循环，在代码中使用for循环会让算法变得非常低效。在深度学习的领域中，我们的数据集是非常非常庞大的，如果使用for循环的话，那么代码的运行会花费很长很长的时间。由于numpy中的dot函数通过计算机硬件实现向量化，所以计算机可以在t0时得到向量w和x的所有值，并且同时将w和x相乘，然后在t1，计算机调用专门的硬件去计算这16个数字的和，而不需要一个接一个的做加法运算了，在大型数据集上使用向量可以更快的更高效的运行算法。</p>\n<p><img src=\"../img/5b716b12afa924718925242cb58365d0.png\" alt=\"在这里插入图片描述\" style=\"zoom:80%;\" /></p>\n<p><strong>举例</strong></p>\n<p>在线性回归的初级版本中，只有一个特征x（房子的大小），可以预测y（房子的价格），所以该模型是fw,b(x)=wx+b，现在不仅考虑这一个特征，还知道其他特征，比如卧室数量、楼层数量以及房子年代来预测房子的价格<br>使用x1 x2 x3 x4来表示这4个特征。</p>\n<p><img src=\"../img/8cf974c7af596277b21039b3b5b4429c.png\" alt=\"在这里插入图片描述\"></p>\n<p><img src=\"../img/935fbb3aa40955715c83ab673efa4672.png\" alt=\"在这里插入图片描述\" style=\"zoom:80%;\" /></p>\n<p><img src=\"../img/804a9fbb10c4a6c496cea68e7ec63b38.png\" alt=\"在这里插入图片描述\" style=\"zoom:80%;\" /></p>\n<p>w和b两个向量之间点积运算，就是w1x1 +w2x2 +w3x3 +……+wnxn<br>下面的表达式和上面的表达式是一样的，点积表示法可以让我们用更少的字符，更紧凑的表示模型。<br>这种具有多个输入特征的线性回归称为多元线性回归，这与只有一个特征变量的回归形成对比，将这个模型称为多元线性回归。</p>\n<h2 id=\"3-2-用于多元线性回归的梯度下降法\"><a href=\"#3-2-用于多元线性回归的梯度下降法\" class=\"headerlink\" title=\"3.2 用于多元线性回归的梯度下降法\"></a>3.2 用于多元线性回归的梯度下降法</h2><p><img src=\"../img/6009f9412e3ee8b8d92242f327615a38.png\" alt=\"在这里插入图片描述\"></p>\n<p><img src=\"../img/6c934860bc7657c1d13c2c88fbb591ef.png\" alt=\"在这里插入图片描述\"></p>\n<h2 id=\"3-3-特征缩放（Feature-Scaling）\"><a href=\"#3-3-特征缩放（Feature-Scaling）\" class=\"headerlink\" title=\"3.3 特征缩放（Feature Scaling）\"></a>3.3 特征缩放（Feature Scaling）</h2><h3 id=\"特征向量（Eigenvector）\"><a href=\"#特征向量（Eigenvector）\" class=\"headerlink\" title=\"特征向量（Eigenvector）\"></a>特征向量（Eigenvector）</h3><p><strong>特征向量：一个向量经过线性变换，仍留在它所张成的空间中</strong></p>\n<p><strong>特征值：描述特征向量经过线性变换后的缩放程度</strong></p>\n<p>大部分的向量经过线性变换都离开了它所张成的空间。 如图中黄色的向量经过线性变换 [3102] ,离开了它所张成的通过原点的直线张成的空间。</p>\n<p><img src=\"../img/videoframe_403.png\" alt=\"videoframe_403\" style=\"zoom:67%;\" /></p>\n<p><img src=\"../img/videoframe_5258.png\" alt=\"videoframe_5258\" style=\"zoom: 67%;\" /></p>\n<p>但是也有一部分向量留在了它所张成的空间，这样线性变换起到的作用就是<strong>压缩或者拉升</strong>如：</p>\n<p>特别的, 对于 [−11] 经过线性变换 [3102] ，相当于将该向量拉升了两倍。</p>\n<p><strong>对于处在它所在的对角线上的任何向量也仅被拉伸了2倍。</strong></p>\n<p><strong>他们的共同点就是线性变换后留在了原来向量所张成的线性空间里边，</strong> 对于其他的向量则离开他原来张成的向量空间</p>\n<p><img src=\"../img/image-20240729174821941.png\" alt=\"image-20240729174821941\" style=\"zoom:50%;\" /></p>\n<p><img src=\"../img/image-20240729174656729.png\" alt=\"image-20240729174656729\" style=\"zoom: 50%;\" /></p>\n<p><strong>因此将这些特殊的向量称为“特征向量” ， 每个特征向量都有一个对应的值，称为“特征值”，目的是衡量特征向量经过变换后的压缩或者拉伸因子。</strong></p>\n<p><img src=\"../img/v2-d3673c170de1e75de55a282112f5dd36_1440w.png\" alt=\"v2-d3673c170de1e75de55a282112f5dd36_1440w\" style=\"zoom: 50%;\" /></p>\n<h3 id=\"特征缩放意义\"><a href=\"#特征缩放意义\" class=\"headerlink\" title=\"特征缩放意义\"></a>特征缩放意义</h3><p>在机器学习算法处理数据时通常是忽略数据的单位信息的，或者说不知道这些数据代表什么。比如50kg和50公里代表着两个不同的度量，人类是很容易区分它们的。但是对于机器来说，这两个数据是一样的。</p>\n<p>特征矩阵各个维度的取值通常是不一样的，此时如果采用欧几里得距离来衡量两个特征的距离，那么最终的距离将严重取决于取值范围跨度大的特征维度，比如说在代表人属性的特征向量有两个维度，分别是年龄和身高，其中年龄的取值范围可以是[1, 100]，身高的取值范围是[0.4, 2.5]（单位：米），那么两个特征向量的距离将严重取决于年龄这个特征，身高基本上对两者的距离没有太大的影响。但通常我们不希望我们的算法一开始就偏向于某个特征。</p>\n<ul>\n<li>数量级的差异将导致量级较大的属性占据主导地位</li>\n<li>数量级的差异将导致迭代收敛速度减慢</li>\n<li>依赖于样本距离的算法对于数据的数量级非常敏感</li>\n</ul>\n<p><strong>好处：</strong></p>\n<ul>\n<li><p>缩放后的特征矩阵，各个维度都具有相同的重要性</p>\n</li>\n<li><p>加快梯度下降，同时防止梯度爆炸(消除过大值的影响)</p>\n</li>\n<li><p>提升模型的精度：在机器学习算法的目标函数中使用的许多元素（例如支持向量机的 RBF 内核或线性模型的 l1 和 l2 正则化)，都是假设所有的特征都是零均值并且具有同一阶级上的方差。如果某个特征的方差比其他特征大几个数量级，那么它就会在学习算法中占据主导位置，导致学习器并不能像我们期望的那样，从其他特征中学习</p>\n</li>\n<li>提升收敛速度：对于线性模型来说，数据归一化后，寻找最优解的过程明显会变得平缓，更容易正确地收敛到最优解</li>\n</ul>\n<h3 id=\"标准化（Standardization-Z-Score-Normalization）\"><a href=\"#标准化（Standardization-Z-Score-Normalization）\" class=\"headerlink\" title=\"标准化（Standardization/Z-Score Normalization）\"></a>标准化（Standardization/Z-Score Normalization）</h3><p>将数据变换为均值为0，标准差为1的分布切记，并非一定是正态的；<br>                                                            <img src=\"../img/e63e27c18f8c59834157b3d2e157434e-172231068666515.png\" alt=\"在这里插入图片描述\"></p>\n<p>Standardization会改变数据的均值、标准差(严格的说，均值和标准差变了，分布也是变了，但分布种类依然没变，原来是啥类型，现在就是啥类型)，实际数据大部分都是正态分布或近似正态，但本质上的分布并不一定是标准正态，完全取决于原始数据是什么分布。</p>\n<h3 id=\"归一化（Rescaling-Normalization）\"><a href=\"#归一化（Rescaling-Normalization）\" class=\"headerlink\" title=\"归一化（Rescaling/Normalization）\"></a>归一化（Rescaling/Normalization）</h3><p>将一列数据变化到某个固定区间(范围)中，通常，这个区间是[0, 1]，广义上，可以是各种区间，比如映射到[0，1]一样可以继续映射到其他范围，图像中可能会映射到[0,255]，其他情况可能映射到[-1,1]；</p>\n<p><img src=\"../img/1f617d854e31660b5553e768b654c247.png\" alt=\"在这里插入图片描述\"></p>\n<h3 id=\"均值归一化-Mean-Normalization\"><a href=\"#均值归一化-Mean-Normalization\" class=\"headerlink\" title=\"均值归一化(Mean Normalization)\"></a>均值归一化(Mean Normalization)</h3><p>将数值范围缩放到[ − 1 , 1 ]区间里，数据的均值变为0 </p>\n<p>​                                                         <img src=\"../img/image-20240730133714958.png\" alt=\"image-20240730133714958\" style=\"zoom: 80%;\" /></p>\n<h3 id=\"差异\"><a href=\"#差异\" class=\"headerlink\" title=\"差异\"></a>差异</h3><p>第一点：显而易见，Normalization会严格的限定变换后数据的范围，比如按之前最大最小值处理的Normalization，它的范围严格在[ 0 , 1 ]之间；<br>而Standardization就没有严格的区间，变换后的数据没有范围，只是其均值是0，标准差为1。</p>\n<p>第二点：归一化(Normalization)对数据的缩放比例仅仅和极值有关，就是说比如100个数，你除去极大值和极小值其他数据都更换掉，缩放比例α=X<sub>max</sub>-X<sub>min</sub>是不变的；反观，对于标准化(Standardization)而言，它的α=σ，β = μ，如果除去极大值和极小值其他数据都更换掉，那么均值和标准差大概率会改变，这时候，缩放比例自然也改变了。</p>\n<p>如果你对处理后的数据范围有严格要求，那肯定是归一化，个人经验，标准化是ML中更通用的手段，如果你无从下手，可以直接使用标准化；如果数据不为稳定，存在极端的最大最小值，不要用归一化。在分类、聚类算法中，需要使用距离来度量相似性的时候、或者使用PCA技术进行降维的时候，标准化表现更好；在不涉及距离度量、协方差计算的时候，可以使用归一化方法。</p>\n<h2 id=\"3-4-多项式回归\"><a href=\"#3-4-多项式回归\" class=\"headerlink\" title=\"3.4 多项式回归\"></a>3.4 多项式回归</h2><p> 多项式回归（Polynomial Regression）是线性回归（Linear Regression）的一种扩展形式。它通过在输入变量上添加高次项来拟合非线性关系。虽然多项式回归本质上还是线性模型，但它允许模型在输入特征的多项式基础上进行线性拟合，从而捕捉复杂的非线性关系。</p>\n<p><img src=\"../img/54f8c47d6b45492d8d6f476104b5de4a.png\" alt=\"img\" style=\"zoom: 67%;\" /></p>\n<p>​              <img src=\"../img/屏幕截图 2024-07-30 174655.png\" alt=\"屏幕截图 2024-07-30 174655\" style=\"zoom: 67%;\" /></p>\n<p><img src=\"../img/image-20240730174933184.png\" alt=\"image-20240730174933184\" style=\"zoom: 67%;\" /></p>\n<p><strong>多项式回归的步骤</strong></p>\n<p><strong>选择多项式的阶数：</strong>选择合适的多项式阶数 n 是模型拟合的关键。阶数过低可能会导致欠拟合，阶数过高则可能导致过拟合。</p>\n<p><strong>构建多项式特征：</strong>将输入特征扩展为多项式特征。例如，对于一个一维特征 x，构建的特征矩阵为</p>\n<p><img src=\"../img/屏幕截图 2024-07-30 142225.png\" alt=\"屏幕截图 2024-07-30 142225\" style=\"zoom: 67%;\" /></p>\n<p><strong>拟合模型：</strong>使用线性回归方法在多项式特征上进行拟合。</p>\n<p><strong>评估模型：</strong>通过均方误差（MSE）等指标评估模型的性能。</p>\n<h2 id=\"3-5-正规方程\"><a href=\"#3-5-正规方程\" class=\"headerlink\" title=\"3.5 正规方程\"></a>3.5 正规方程</h2><p>正规方程公式：</p>\n<p><img src=\"../img/5fb8dc091ac83d01add801bc3654e7a0-172233044663219.png\" alt=\"在这里插入图片描述\" style=\"zoom:50%;\" /></p>\n<p> y，其中 是特征值矩阵，y是目标值矩阵。</p>\n<p>优点：正规方程可以直接求出最好结果（即最小损失）</p>\n<p>缺点：由于涉及到矩阵运算，当特征过多时矩阵运算变得很复杂，求解速度会很慢。所以只适用于小数据量。</p>\n<p><img src=\"../img/7f4e90b5fe08a1dba7e4a7fda7cf8510.png\" alt=\"img\" style=\"zoom:50%;\" /></p>\n<p><img src=\"../img/5cd9533c1cf6aa74997140dc65fd7f09.png\" alt=\"在这里插入图片描述\" style=\"zoom: 50%;\" /></p>\n<hr>\n<h1 id=\"四、逻辑回归（Logistic-Regression）\"><a href=\"#四、逻辑回归（Logistic-Regression）\" class=\"headerlink\" title=\"四、逻辑回归（Logistic Regression）\"></a>四、逻辑回归（Logistic Regression）</h1><h2 id=\"4-1-理论推导\"><a href=\"#4-1-理论推导\" class=\"headerlink\" title=\"4.1 理论推导\"></a>4.1 理论推导</h2><p>线性回归拟合的是数值，并不符合我们预测类别的需求。但数值与类别也是有关联的。例如，天色越黑，下雨概率就越大。即值越大，属于某类别的概率也越大。值与概率之间可以互转。</p>\n<p><strong>1、问题描述和转化</strong></p>\n<ul>\n<li>一个二分类问题给的条件：</li>\n</ul>\n<p>分类标签Y {0，1}，特征自变量X{x1，x2，……，xn}</p>\n<p>如何根据我们现在手头上有的特征X来判别它应该是属于哪个类别（0还是1）</p>\n<ul>\n<li>问题的求解转化为：</li>\n</ul>\n<p>我们如何找一个模型，即一个关于X的函数来得出分类结果（0或1）</p>\n<p><strong>2、初步思路：找一个线性模型来由X预测Y</strong></p>\n<p><img src=\"../img/eq.png\" alt=\"z = w^{T}x+b\"></p>\n<p>但是很明显，这样的函数图像是类似一条斜线，难以达到我们想要的（0或1）的取值</p>\n<p>所以我们引入了一个特殊的函数：</p>\n<p><strong>3、Sigmoid函数（逻辑函数）</strong><br>公式</p>\n<p><img src=\"../img/dfrac{1}{1&plus;e^{-x}}.png\" alt=\"\\textbf{Sigmoid}(x) = \\dfrac{1}{1+e^{-x}}\"></p>\n<p>函数图像</p>\n<p><img src=\"../img/e3196d5cf98925c6a819c84485b27fb5.png\" alt=\"img\"></p>\n<p><strong>4、刚刚的线性模型与Sigmoid函数合体</strong></p>\n<p><img src=\"../img/frac{1}{1&plus;e^{-z}}.png\" alt=\"g(z)=\\frac{1}{1+e^{-z}}\"></p>\n<p>这样我们就把取值控制在了0或1上，初步达成了我们的目标。</p>\n<p><strong>5、条件概率</strong></p>\n<p>我们令 <img src=\"../img/boldsymbol{w}^{T} X&plus;b}}.png\" alt=\"y = \\frac{1}{1+e^{-\\boldsymbol{w}^{T} X+b}}\">，则可得 <img src=\"../img/boldsymbol{w}^{T} X&plus;b.png\" alt=\"ln \\frac{y}{1-y}= \\boldsymbol{w}^{T} X+b\"></p>\n<p>若我们将y视为样本x作为正例的概率，那么1-y则为样本x作为反例的概率，二者的比值为<img src=\"../img/frac{y}{1-y}.png\" alt=\"\\frac{y}{1-y}\">，</p>\n<p>因此 <img src=\"../img/frac{y}{1-y}-172240362929339.png\" alt=\"ln \\frac{y}{1-y}\"> 被称为对数几率。</p>\n<p>因此有：<img src=\"../img/boldsymbol{w}^{T} X&plus;b-172240362929340.png\" alt=\"ln \\frac{p(y=1|x)}{p(y=0|x)}= \\boldsymbol{w}^{T} X+b\"></p>\n<p>所以推出了：</p>\n<p><img src=\"../img/image-20240731132719314.png\" alt=\"image-20240731132719314\" style=\"zoom: 67%;\" /></p>\n<p>可化简为：</p>\n<p><img src=\"../img/ed0a6e081dd58f4205596e406279decd.png\" alt=\"img\"></p>\n<p><img src=\"../img/21841e0a084683926f12b6784399670f.png\" alt=\"img\"></p>\n<p>假设每个样本是独立事件，则总评估正确的概率为所有样本评估正确的积：</p>\n<p><img src=\"../img/fc0fa6619e0c962cd2de9e354eb90f3d.png\" alt=\"img\"></p>\n<p><img src=\"../img/a05d800d6242c29c5f3038406e07caee.png\" alt=\"a05d800d6242c29c5f3038406e07caee\"></p>\n<p> <strong>损失函数</strong></p>\n<p><img src=\"../img/image-20240731144102228.png\" alt=\"image-20240731144102228\" style=\"zoom:67%;\" /></p>\n<p><img src=\"../img/7c7762b9496771b1866f01c22ce34a02.png\" alt=\"在这里插入图片描述\" style=\"zoom: 80%;\" /></p>\n<p><strong>求最小值时的w</strong></p>\n<p>梯度下降法（一阶收敛）</p>\n<p>通过 J(w) 对 w 的一阶导数来找下降方向，并以迭代的方式来更新参数</p>\n<p><img src=\"../img/image-20240731152409237.png\" alt=\"image-20240731152409237\" style=\"zoom:67%;\" /></p>\n<p>(这里的k代表的是第k次迭代；<img src=\"../img/alpha.png\" alt=\"\\alpha\">是我们设定的学习率；<img src=\"../img/eq.png\" alt=\"p(x_{i})\">就是我们上面所说的<img src=\"../img/eq-17224106347532.png\" alt=\"P(Y|X_{i})\"> )</p>\n<h2 id=\"4-2-决策边界（Decision-Boundary）\"><a href=\"#4-2-决策边界（Decision-Boundary）\" class=\"headerlink\" title=\"4.2 决策边界（Decision Boundary）\"></a>4.2 决策边界（Decision Boundary）</h2><p>利用训练好的模型对样本空间所有的坐标点进行预测，然后观察样本空间所有点的不同类别之间的边界，最终就是模型的决策边界。</p>\n<p>在二分类问题中，决策边界或决策表面是超曲面，其将基础向量空间划分为两个集合，一个集合。 <strong>分类器将决策边界一侧的所有点分类为属于一个类，而将另一侧的所有点分类为属于另一个类。</strong>可以通过绘制模型决策边界，来辅助判别分类模型的模型性能。</p>\n<p>不同模型的决策边界并不相同，逻辑回归在二维样本空间中的决策边界是一条直线，KNN模型决策边界实际上是一个个圆圈叠加而成的拥有一定幅度的边界，而对于决策树模型来说，其决策边界实际上是一条条折线。</p>\n<p>基于反向传播的人工神经网络或感知器的情况下，网络可以学习的决策边界的类型由网络具有的隐藏层的数量来确定。如果它没有隐藏层，那么它只能学习线性问题。如果它有一个隐藏层，则它可以学习Rn的紧致子集上的任何连续函数 ，如通用近似定理所示，因此它可以具有任意的决策边界。</p>\n<p>神经网络试图学习决策边界，最小化经验误差，而支持向量机试图学习决策边界，最大化决策边界和数据点之间的经验边际。</p>\n<p><strong>阈值</strong></p>\n<p>阈值的理解可以浅显的认为，相当于一个边界线，大于这个边界线是一个结果，小于这个边界线则是另一个结果。在逻辑回归中，大于这个边界线就是1，小于这个边界线则就是0。</p>\n<p><strong>拿 sigmoid 函数举例</strong></p>\n<p>当 x = 0 时为 sigmoid function 的决策边界。<br>即所有 x &gt; 0 的部分 g ( x ) = 1，所有 x &lt; 0的部分 g ( x ) = 0。<br><img src=\"../img/742a64f03678feae597e0efaf3d51ab6.jpeg\" alt=\"在这里插入图片描述\" style=\"zoom: 50%;\" /></p>\n<p><strong>引用到 逻辑回归</strong></p>\n<p>decision boundary为 z = 0 z=0z=0 的时候，即 0.5 x + 1 = 0 0.5x+1=00.5x+1=0 时。<br><img src=\"../img/3f2dca2e783b164b46053c3f6cf9261c.jpeg\" alt=\"在这里插入图片描述\" style=\"zoom:50%;\" /></p>\n<h1 id=\"五、正则化（Regularization）\"><a href=\"#五、正则化（Regularization）\" class=\"headerlink\" title=\"五、正则化（Regularization）\"></a>五、正则化（Regularization）</h1><h2 id=\"5-1-过拟合（overfitting）、欠拟合（underfitting）\"><a href=\"#5-1-过拟合（overfitting）、欠拟合（underfitting）\" class=\"headerlink\" title=\"5.1 过拟合（overfitting）、欠拟合（underfitting）\"></a>5.1 过拟合（overfitting）、欠拟合（underfitting）</h2><p><strong>回归模型：</strong></p>\n<p><img src=\"../img/a602679b63fd32d8deeb240269a5f343.png\" alt=\"img\" style=\"zoom:50%;\" /></p>\n<p><strong>分类模型：</strong></p>\n<p><img src=\"../img/d3572f0e078ff589a35043c786c074e7.png\" alt=\"img\" style=\"zoom:50%;\" /></p>\n<p><img src=\"../img/86ea53bb303e677f0fe8af060478a43c-172250580805811.png\" alt=\"img\" style=\"zoom:50%;\" /></p>\n<p><strong>欠拟合</strong></p>\n<p>泛化能力差，拟合程度比较低，训练样本集准确率低，测试样本集准确率低。</p>\n<p><strong>欠拟合原因：</strong></p>\n<ul>\n<li>训练样本数量少</li>\n<li>模型复杂度过低</li>\n<li>参数还未收敛就停止循环</li>\n</ul>\n<p><strong>欠拟合的解决办法：</strong></p>\n<ul>\n<li>增加样本数量</li>\n<li>增加模型参数，提高模型复杂度</li>\n<li>增加循环次数</li>\n<li>查看是否是学习率过高导致模型无法收敛</li>\n</ul>\n<p><strong>过拟合</strong></p>\n<p>泛化能力差，拟合程度非常高，训练样本集准确率高，测试样本集准确率低。</p>\n<p><strong>过拟合原因：</strong></p>\n<ul>\n<li>样本量少、样本噪声大（质量不好）</li>\n<li>特征太多</li>\n<li>模型太复杂或模型本身就不适用</li>\n<li>网络层数过多，导致后面学习得到的特征不够具有代表性</li>\n</ul>\n<p><strong>过拟合的表现（判定方法）：</strong></p>\n<ul>\n<li><p>训练集的正确率不增反减</p>\n</li>\n<li><p>验证集的正确率不再发生变化</p>\n</li>\n<li><p>训练集的error一直下降，但是验证集的error不减反增</p>\n</li>\n</ul>\n<p><strong>过拟合的解决办法：</strong></p>\n<ul>\n<li>清洗数据</li>\n<li>减少模型参数，降低模型复杂度，包括greedy constructive learning、剪枝和权重共享等</li>\n<li>增加惩罚因子（正则化），保留所有的特征，但是减少参数的大小（magnitude）。</li>\n</ul>\n<h2 id=\"5-2-正则化方法\"><a href=\"#5-2-正则化方法\" class=\"headerlink\" title=\"5.2 正则化方法\"></a>5.2 正则化方法</h2><h3 id=\"5-2-1-L1-正则化\"><a href=\"#5-2-1-L1-正则化\" class=\"headerlink\" title=\"5.2.1 L1 正则化\"></a>5.2.1 L1 正则化</h3><p>也称为 Lasso 正则化，是指权值向量w中各个元素的绝对值之和。比如 向量A=[1，-1，3]， 那么A的L1范数为 |1|+|-1|+|3|。它通过在模型的损失函数中增加权重的 L1 范数（权重向量的绝对值之和）来实现正则化。L1正则化可以让一部分特征的系数缩小到0，所以L1适用于特征之间有关联的情况可以产生稀疏权值矩阵（很多权重为0，则一些特征被过滤掉），即产生一个稀疏模型，可以用于特征选择。</p>\n<p><strong>L1 正则化</strong>是一种通过在模型的损失函数中增加权重的 <strong>L1 范数作为惩罚项</strong>来控制模型复杂度的技术。L1 范数是向量中各个元素的绝对值之和，其数学表示如下：</p>\n<p><img src=\"../img/sum_{i%3D1}^{n} w_i.png\" alt=\"||\\mathbf{w}||_1 = \\sum_{i=1}^{n} |w_i|\"></p>\n<p><strong>惩罚项可以写为权重的 L1 范数：</strong></p>\n<p><img src=\"../img/mathbf{w}_1.png\" alt=\"\\text{penalty} = \\lambda ||\\mathbf{w}||_1\"></p>\n<p>其中 w是模型的权重向量，n是权重向量的长度，即权重的数量， λ是正则化参数，用于控制正则化的强度。</p>\n<p><strong>线性回归L1正则化损失函数：</strong></p>\n<p><img src=\"../img/image-20240804224723075.png\" alt=\"image-20240804224723075\" style=\"zoom:33%;\" /></p>\n<p>正则化是权值的绝对值之和，所以L1是带有绝对值符号的函数，因此是不完全可微的。机器学习的任务就是要通过一些方法（比如梯度下降）求出损失函数的最小值。当我们在原始损失函数后添加L1正则化项时，相当于对损失函数做了一个约束。</p>\n<p>L1正则化可以使得参数稀疏化，即得到的参数是一个稀疏矩阵，可以用于特征选择。</p>\n<p><strong>稀疏性</strong>，就是模型的很多参数是0。通常机器学习中特征数量很多，例如文本处理时，如果将一个词组（term）作为一个特征，那么特征数量会达到上万个（bigram）。在预测或分类时，那么多特征显然难以选择，但是如果代入这些特征得到的模型是一个稀疏模型，很多参数是0，表示只有少数特征对这个模型有贡献，绝大部分特征是没有贡献的，即使去掉对模型也没有什么影响，此时我们就可以只关注系数是非零值的特征。这相当于对模型进行了一次特征选择，只留下一些比较重要的特征，提高模型的泛化能力，降低过拟合的可能。</p>\n<h3 id=\"5-2-2-L2-正则化\"><a href=\"#5-2-2-L2-正则化\" class=\"headerlink\" title=\"5.2.2 L2 正则化\"></a>5.2.2 L2 正则化</h3><p>也称为 Ridge 正则化，它通过在模型的损失函数中增加权重的 L2 范数（权重向量的平方和）来实现正则化。L2 正则化会使权重值变得较小，但不会直接导致权重稀疏，因此不具有特征选择的作用，但可以有效地控制模型的复杂度。</p>\n<p><strong>L2正则化</strong>通过向模型的<strong>损失函数添加一个权重参数的 L2 范数的惩罚项</strong>来实现。用 L2 正则化的损失函数时，优化算法在优化过程中会同时考虑数据损失和正则化项，从而在保持对训练数据的拟合能力的同时，尽可能减小模型参数的大小，降低模型的复杂度。</p>\n<p><strong>线性回归L2正则化损失函数：</strong></p>\n<p><img src=\"../img/image-20240804224802117.png\" alt=\"image-20240804224802117\" style=\"zoom:67%;\" /></p>\n<p><strong>拟合过程中通常都倾向于让权值尽可能小，数据偏移得多一点也不会对结果造成什么影响，抗扰动能力强</strong>。</p>\n<p><strong>L2正则化获得更小参数过程：</strong></p>\n<p>(1) 以线性回归中的梯度下降法为例。假设要求的参数为θ，hθ(x)是假设函数，线性回归的代价函数如下：</p>\n<p><img src=\"../img/image-20240804224821245.png\" alt=\"image-20240804224821245\" style=\"zoom:67%;\" /></p>\n<p>(2)在梯度下降中θ的迭代公式为：</p>\n<p><img src=\"../img/image-20240804224640729.png\" alt=\"image-20240804224640729\" style=\"zoom: 25%;\" /></p>\n<p>(3)在原始代价函数之后添加L2正则化，则迭代公式为：</p>\n<p><img src=\"../img/image-20240804225244597.png\" alt=\"image-20240804225244597\" style=\"zoom: 50%;\" /></p>\n<p>从上式可以看到，与未添加L2正则化的迭代公式相比，每一次迭代，θj都要先乘以一个小于1的因子，从而使得θj不断减小，因此总得来看，θ是不断减小的。</p>\n<p><strong>调参经验</strong><br>从0开始，逐渐增大λ。在训练集上学习到参数，然后在测试集上验证误差。反复进行这个过程，直到测试集上的误差最小。一般的说，随着λ从0开始增大，测试集的误分类率应该是先减小后增大，交叉验证的目的，就是为了找到误分类率最小的那个位置。建议一开始将正则项系数λ设置为0，先确定一个比较好的learning rate。然后固定该learning rate，给λ一个值（比如1.0），然后根据validation accuracy，将λ增大或者减小10倍，增减10倍是粗调节，当你确定了λ的合适的数量级后，比如λ=0.01，再进一步地细调节，比如调节为0.02，0.03，0.009之类。</p>\n<h3 id=\"5-2-3-Dropout\"><a href=\"#5-2-3-Dropout\" class=\"headerlink\" title=\"5.2.3 Dropout\"></a>5.2.3 Dropout</h3><p>可先跳至神经网络一章</p>\n<p>正常神经网络需要对每一个节点进行学习，而添加了DropOut的神经网络先随机选择中的一些神经元并将其临时隐藏(丢弃)，即暂时将其从网络中移除，以及它的所有传入和传出连接。在下一次迭代中，继续随机隐藏一些神经元，如此直至训练结束。由于是随机丢弃，故而每一个mini-batch都在训练不同的网络。</p>\n<p>将DropOut应用于神经网络相当于从神经网络中采样了一个“更薄的”网络，即单元个数较少。（如下图所示，DropOut是从左图采样了一个右图这样更薄的网络）在正反向传播的过程中，采样了多个稀薄网络，即Dropout可以解释为模型平均的一种形式。</p>\n<p><img src=\"../img/986023-20191007192820707-1056572897.png\" alt=\"img\"></p>\n<p>　在训练时，每个神经单元以概率pp被保留(Dropout丢弃率为1−p)；在预测阶段（测试阶段），每个神经单元都是存在的，权重参数w要乘以p，输出是：pw。</p>\n<p><strong>模型描述</strong></p>\n<p><strong>前提</strong>：带有L层隐藏层的神经网络。</p>\n<p><strong>l</strong>：第几层。<br><strong>z</strong>： 代表输入向量<br><strong>y</strong>： 代表输出向量<br><strong>W</strong>：代表权重<br><strong>b</strong>：偏差<br><strong>f</strong>： 激活函数</p>\n<p><strong>没有DropOut的神经网络前向传播计算公式可以被描述为</strong>：l+1层的输入向量是l+1的权重乘以l层的输出向量加l+1层的偏差。l+1层的输出向量为经过激活函数的l+1层的输入向量。</p>\n<p><img src=\"../img/image-20240805140155824.png\" alt=\"image-20240805140155824\" style=\"zoom: 67%;\" /></p>\n<p><strong>添加DropOut的神经网络前向传播计算公式可以被描述为</strong>：相比于之前输出向量经过了伯努利分布，类似于经过一个门筛选了一下。*代表的是点积。</p>\n<p><img src=\"../img/image-20240805140217677.png\" alt=\"image-20240805140217677\" style=\"zoom:67%;\" /></p>\n<p><strong>神经网络图描述</strong></p>\n<p><strong>神经网络图示如下所示</strong>：上图为标准的神经网络，下图为添加了Dropout的神经网络，相比于标准的神经网络，添加了Dropout的神经网络相当于为前一层的输出向量添加了一道概率流程，即是否经过筛选。</p>\n<p><img src=\"../img/image-20240805140321072.png\" alt=\"image-20240805140321072\" style=\"zoom:67%;\" /></p>\n<p><img src=\"../img/image-20240805140350886.png\" alt=\"image-20240805140350886\" style=\"zoom: 67%;\" /></p>\n<p><strong>防止过拟合原因</strong></p>\n<p><strong>（1）取平均的作用</strong> </p>\n<p>　　先回到标准的模型即没有dropout，我们用相同的训练数据去训练5个不同的神经网络，一般会得到5个不同的结果，此时我们可以采用 “5个结果取均值”或者“多数取胜的投票策略”去决定最终结果。例如3个网络判断结果为数字9,那么很有可能真正的结果就是数字9，其它两个网络给出了错误结果。这种“综合起来取平均”的策略通常可以有效防止过拟合问题。因为不同的网络可能产生不同的过拟合，取平均则有可能让一些“相反的”拟合互相抵消。dropout掉不同的隐藏神经元就类似在训练不同的网络，随机删掉一半隐藏神经元导致网络结构已经不同，整个dropout过程就相当于对很多个不同的神经网络取平均。而不同的网络产生不同的过拟合，一些互为“反向”的拟合相互抵消就可以达到整体上减少过拟合。</p>\n<p><strong>（2）减少神经元之间复杂的共适应关系</strong></p>\n<p>　　用作者原话是“在标准神经网络中，每个参数接收的导数表明其应该如何变化才能使最终损失函数降低，并给定所有其它神经网络单元的状态。因此<strong>神经单元可能以一种可以修正其它神经网络单元的错误的方式进行改变。而这就可能导致复杂的共适应(co-adaptations)</strong>。由于这些共适应现象没有推广到未见的数据，将导致过拟合。我们假设对每个隐藏层的神经网络单元，Dropout通过使其它隐藏层神经网络单元不可靠从而阻止了共适应的发生。因此，一个隐藏层神经元不能依赖其它特定神经元去纠正其错误。”</p>\n<p>　　 因为dropout程序导致两个神经元不一定每次都在一个dropout网络中出现。这样权值的更新不再依赖于有固定关系的隐含节点的共同作用，阻止了某些特征仅仅在其它特定特征下才有效果的情况 。迫使网络去学习更加鲁棒的特征 ，这些特征在其它的神经元的随机子集中也存在。换句话说假如我们的神经网络是在做出某种预测，它不应该对一些特定的线索片段太过敏感，即使丢失特定的线索，它也应该可以从众多其它线索中学习一些共同的特征。从这个角度看dropout就有点像L1，L2正则，减少权重使得网络对丢失特定神经元连接的鲁棒性提高。</p>\n<p><strong>（3）Dropout类似于性别在生物进化中的角色</strong></p>\n<p>　　物种为了生存往往会倾向于适应这种环境，环境突变则会导致物种难以做出及时反应，性别的出现可以繁衍出适应新环境的变种，有效的阻止过拟合，即避免环境改变时物种可能面临的灭绝。</p>\n<hr>\n<h1 id=\"六、神经网络（Neural-Network）\"><a href=\"#六、神经网络（Neural-Network）\" class=\"headerlink\" title=\"六、神经网络（Neural Network）\"></a>六、神经网络（Neural Network）</h1><h2 id=\"6-1-前言\"><a href=\"#6-1-前言\" class=\"headerlink\" title=\"6.1 前言\"></a>6.1 前言</h2><p>神经网络主要由：<strong>输入层，隐藏层，输出层</strong>构成。当隐藏层只有一层时，该网络为两层神经网络，由于输入层未做任何变换，可以不看做单独的一层。实际中，网络输入层的每个神经元代表了一个特征，输出层个数代表了分类标签的个数（在做二分类时，如果采用sigmoid分类器，输出层的神经元个数为1个；如果采用softmax分类器，输出层神经元个数为2个；如果是多分类问题，即输出类别&gt;=3时，输出层神经元为类别个数），而隐藏层层数以及隐藏层神经元是由人工设定。一个基本的两层神经网络可见下图（注意：说神经网络多少层数的时候一般不包括输入层。 在神经网络中的激活主要讲的是梯度的更新的激活）：</p>\n<p><img src=\"..../img/ec01486fd81a42733d3acef52a95c907.png\" alt=\"img\" style=\"zoom:50%;\" /></p>\n<p>神经元模型是一个包含输入，输出与计算功能的模型。输入可以类比为神经元的树突，而输出可以类比为神经元的轴突，计算则可以类比为细胞核。</p>\n<p>　　下图是一个典型的神经元模型：包含有3个输入，1个输出，以及2个计算功能。</p>\n<p>　　注意中间的箭头线。这些线称为“连接”。每个上有一个“权值”。</p>\n<p><img src=\"../img/75b9760fdd6dc27daf143454b9749fd1.png\" alt=\"img\" style=\"zoom: 67%;\" /></p>\n<p>我们使用a来表示输入，用w来表示权值。一个表示连接的有向箭头可以这样理解：在初端，传递的信号大小仍然是a，端中间有加权参数w，经过这个加权后的信号会变成a * w。</p>\n<p><img src=\"../img/5edde0590ebecbb366852259ce371054.png\" alt=\"img\" style=\"zoom:67%;\" /></p>\n<p>在MP模型里，函数g是sgn函数，也就是取符号函数。这个函数当输入大于0时，输出1，否则输出0。</p>\n<p>　　下面对神经元模型的图进行一些扩展。首先将sum函数与sgn函数合并到一个圆圈里，代表神经元的内部计算。其次，把输入a与输出z写到连接线的左上方，便于后面画复杂的网络。最后说明，一个神经元可以引出多个代表输出的有向箭头，但值都是一样的。</p>\n<p>　　神经元可以看作一个计算与存储单元。计算是神经元对其的输入进行计算功能。存储是神经元会暂存计算结果，并传递到下一层。</p>\n<p><img src=\"../img/1159ca7927d03a090e353bf2377deb02.png\" alt=\"img\" style=\"zoom:67%;\" /></p>\n<p>当我们用“神经元”组成网络以后，描述网络中的某个“神经元”时，我们更多地会用“<strong>单元</strong>”（unit）来指代。同时由于神经网络的表现形式是一个有向图，有时也会用“<strong>节点</strong>”（node）来表达同样的意思。 </p>\n<h2 id=\"6-2-单层神经网络（感知器-Perception）\"><a href=\"#6-2-单层神经网络（感知器-Perception）\" class=\"headerlink\" title=\"6.2 单层神经网络（感知器 Perception）\"></a>6.2 单层神经网络（感知器 Perception）</h2><p>在“感知器”中，有两个层次。分别是输入层和输出层。输入层里的“输入单元”只负责传输数据，不做计算。输出层里的“输出单元”则需要对前面一层的输入进行计算。</p>\n<p>在原来MP模型的“输入”位置添加神经元节点，标志其为“输入单元”。其余不变，于是我们就有了下图：从本图开始，我们将权值w1, w2, w3写到“连接线”的中间。</p>\n<p><img src=\"../img/938b7c669240a4250c46f46cde645aab.png\" alt=\"img\" style=\"zoom: 67%;\" /></p>\n<p><strong>下图显示了带有两个输出单元的单层神经网络</strong></p>\n<p><img src=\"../img/53c8c4855619cd0dc1515864c7eb00fe.png\" alt=\"img\" style=\"zoom:50%;\" /></p>\n<p><img src=\"../img/93a50fc810d72c81957baff6032d7756.png\" alt=\"img\" style=\"zoom:50%;\" /></p>\n<p><img src=\"../img/8d37f29e30331a1367b9c4156f9ba1a9.png\" alt=\"img\" style=\"zoom: 50%;\" /></p>\n<p>输入的变量是[a1，a2，a3]T（代表由a1，a2，a3组成的列向量），用向量<strong>a</strong>来表示。方程的左边是[z1，z2]T，用向量<strong>z</strong>来表示。</p>\n<p>系数则是矩阵<strong>W</strong>（2行3列的矩阵，排列形式与公式中的一样）。</p>\n<p>于是，输出公式可以改写成： g(<strong>W</strong> <em> <strong>a</strong>) = <em>*z</em></em>;</p>\n<h2 id=\"6-3-两层神经网络（多层感知器MLP-Multilayer-Perceptron）\"><a href=\"#6-3-两层神经网络（多层感知器MLP-Multilayer-Perceptron）\" class=\"headerlink\" title=\"6.3 两层神经网络（多层感知器MLP Multilayer Perceptron）\"></a>6.3 两层神经网络（多层感知器MLP Multilayer Perceptron）</h2><p>两层神经网络除了包含一个输入层，一个输出层以外，还增加了一个中间层。此时，中间层和输出层都是计算层。</p>\n<p><img src=\"../img/bd5d018f58f101c7b8341a0bc996cc1c.png\" alt=\"img\" style=\"zoom:50%;\" /></p>\n<p><img src=\"../img/ff6b58c6dc41f9f439a8ceaa9393757c.png\" alt=\"img\" style=\"zoom:50%;\" /></p>\n<p><strong>矩阵计算公式：</strong></p>\n<p> g(<strong>W</strong>(1) <em> <strong>a</strong>(1)) = <em>*a</em></em>(2)</p>\n<p>g(<strong>W</strong>(2) <em> <strong>a</strong>(2)) = <em>*z</em></em></p>\n<p>偏置节点（bias unit）是默认存在的。它本质上是一个只含有存储功能，且存储值永远为1的单元。在神经网络的每个层次中，除了输出层以外，都会含有这样一个偏置单元。正如线性回归模型与逻辑回归模型中的一样。</p>\n<p>偏置单元与后一层的所有节点都有连接，我们设这些参数值为向量<strong>b</strong></p>\n<p><img src=\"../img/c2c8420cff26253a2a0ff71ed9b9ab2c.png\" alt=\"img\" style=\"zoom:50%;\" /></p>\n<p><strong>矩阵运算公式：</strong></p>\n<p>g(<strong>W</strong>(1) <em> <strong>a</strong>(1) + <strong>b</strong>(1)) = <em>*a</em></em>(2)</p>\n<p>g(<strong>W</strong>(2) <em> <strong>a</strong>(2) + <strong>b</strong>(2)) = <em>*z</em></em></p>\n<p>在两层神经网络中，我们不再使用sgn函数作为函数g，而是使用平滑函数sigmoid作为函数g</p>\n<h2 id=\"6-4-普通多层神经网络\"><a href=\"#6-4-普通多层神经网络\" class=\"headerlink\" title=\"6.4 普通多层神经网络\"></a>6.4 普通多层神经网络</h2><p>在两层神经网络的输出层后面，继续添加层次。原来的输出层变成中间层，新加的层次成为新的输出层。所以可以得到下图。</p>\n<p>依照这样的方式不断添加，我们可以得到更多层的多层神经网络。公式推导的话其实跟两层神经网络类似，使用矩阵运算的话就仅仅是加一个公式而已。</p>\n<p>在已知输入<strong>a</strong>(1)，参数<strong>W</strong>(1)，<strong>W</strong>(2)，<strong>W</strong>(3)的情况下，输出<strong>z</strong>的推导公式如下：</p>\n<p>g(<strong>W</strong>(1) <em> <strong>a</strong>(1)) = <em>*a</em></em>(2); </p>\n<p>g(<strong>W</strong>(2) <em> <strong>a</strong>(2)) = <em>*a</em></em>(3);</p>\n<p>g(<strong>W</strong>(3) <em> <strong>a</strong>(3)) = <em>*z</em></em>;</p>\n<p><img src=\"../img/5b22532fd29fc20b299488fa55e22890.png\" alt=\"img\" style=\"zoom:50%;\" /></p>\n<p><strong>W</strong>(1)中有6个参数，<strong>W</strong>(2)中有4个参数，<strong>W</strong>(3)中有6个参数，所以整个神经网络中的参数有16个（这里我们不考虑偏置节点，下同）。</p>\n<p>假设我们将中间层的节点数做一下调整。第一个中间层改为3个单元，第二个中间层改为4个单元。</p>\n<p>经过调整以后，整个网络的参数变成了33个。</p>\n<p><img src=\"../img/66c2a2d5e23e80feed37dd9ae11bc2dd.png\" alt=\"img\" style=\"zoom: 50%;\" /></p>\n<p><img src=\"../img/6ba733ace1a889077da6be464e6720ca.png\" alt=\"img\"></p>\n<h2 id=\"6-5-激活函数（Activation-Function）\"><a href=\"#6-5-激活函数（Activation-Function）\" class=\"headerlink\" title=\"6.5 激活函数（Activation Function）\"></a>6.5 激活函数（Activation Function）</h2><p>神经元中使用的函数，在术语上通常叫做激活函数。主要的激活函数有step,sigmoid,softmax,tanh和ReLU等</p>\n<p>每一个隐藏层可以有一个不同的激活函数，例如，在同一个神经网络中，隐藏层layer1可能使用sigmoid函数，隐藏层layer2可能使用ReLU，后续的隐藏层layer3使用Tanh。激活函数的选择取决于待解决的问题以及使用的数据的类型。</p>\n<p><strong>阶跃函数</strong></p>\n<p><img src=\"../img/4e6gfcaxeg.png\" alt=\"img\"></p>\n<p>其中，如果x的值大于等于零，则输出为1；如果x的值小于零，则输出为0。我们可以看到阶跃函数在零点是不可微的。目前，神经网络采用反向传播法和梯度下降法来计算不同层的权重。由于阶跃函数在零处是不可微的，因此它并不适用于梯度下降法，并且也不能应用在更新权重的任务上。 为了克服这个问题，我们引入了sigmoid函数。</p>\n<p><strong>Sigmoid函数</strong></p>\n<p><img src=\"../img/5m82piwrzk.png\" alt=\"img\"></p>\n<p>当z或自变量趋于负无穷大时，函数的值趋于零；当z趋于正无穷大时，函数的值趋于1。该函数表示因变量行为的近似值，并且是一个假设。</p>\n<p>用Sigmoid函数作为近似函数之一的原因：</p>\n<ol>\n<li><p>它在可以捕获数据的非线性。虽然是一个近似的形式，但非线性的概念是模型精确的重要本质。</p>\n</li>\n<li><p>sigmoid函数在整个过程中是可微的，因此可以与梯度下降和反向传播方法一起使用，以计算不同层的权重。</p>\n</li>\n<li><p>假设一个因变量服从一个sigmoid函数的固有假设的高斯分布的自变量，这是一个一般分布，我们可以获得许多随机发生的事件，这是一个好的的一般分布开始。</p>\n</li>\n</ol>\n<p>然而，sigmoid函数也面临着梯度消失的问题。从图中可以看出，一个sigmoid函数将其输入压缩到一个非常小的输出范围[0,1]，并具有非常陡峭的渐变。因此，输入空间中仍然有很大的区域，即使是很大的变化也会在输出中产生很小的变化。这被称为梯度消失问题。这个问题随着层数的增加而增加，从而使神经网络的学习停留在一定的水平上。</p>\n<p><strong>Softmax函数</strong></p>\n<p>softmax函数是用于多类分类问题的激活函数，在多类分类问题中，超过两个类标签则需要类成员关系。对于长度为K的任意实向量，Softmax函数可以将其压缩为长度为K，值在[ 0 , 1 ] 范围内，并且向量中元素的总和为1的实向量。 softmax 对向量进行操作，而 sigmoid 则采用标量。<br>                                                                  <img src=\"../img/image-20240809114037841.png\" alt=\"image-20240809114037841\" style=\"zoom:67%;\" /></p>\n<p>Softmax函数与正常的max函数不同：max函数仅输出最大值，但Softmax函数确保较小的值具有较小的概率，并且不会直接丢弃。</p>\n<p><strong>Tanh函数</strong></p>\n<p>Tanh(z)函数是sigmoid函数的缩放版本，它的输出范围变成了[-1,1]，而不是[0,1].当数据分布在0周围时，其导数值更高。一个更高的梯度对于更好的学习速率更有帮助</p>\n<p><img src=\"../img/26s4k121qn.jpeg\" alt=\"img\" style=\"zoom:67%;\" /></p>\n<p><img src=\"../img/image-20240806160312030.png\" alt=\"image-20240806160312030\"></p>\n<p><strong>ReLU函数</strong></p>\n<p>在深度学习模型中，修正线性单元(ReLU)是最常用的激活函数。当函数输入负数时，函数输出0，对于任意正数x，函数输出本身。因此它可以写成f(x)=max(0,x)</p>\n<p><img src=\"../img/hxm1q5pjil.png\" alt=\"img\"></p>\n<p>Leaky ReLU是一个其中最出名的一种变形，对于正数输入，其输出和ReLU一样，但是对于所有负数输出，不再是0，而是具有一个常数斜率（小于1）.</p>\n<ul>\n<li>这个斜率是在构建模型时，需要使用者设置的参数。它通常被叫做alpha，例如，使用者设置alpha=0.3.这个激活函数则表示为f(x)=max(0.3x,x)。这具有一个理论优点，通过x在所有值处都能有一个影响，使得在x中包含的信息被充分利用。</li>\n</ul>\n<p>激活函数还有有其他可以替代的选择，但是对于从业者和研究人员，发现一般情况通过改变使用其他激活函数代替ReLU，并不能带来足够的收益。在平常实践中，ReLU比Sigmoid或者tanh函数表现的更好。</p>\n<h2 id=\"6-6-代价函数\"><a href=\"#6-6-代价函数\" class=\"headerlink\" title=\"6.6 代价函数\"></a>6.6 代价函数</h2><h3 id=\"6-6-1-交叉熵代价函数（Cross-entropy-Loss-Function）\"><a href=\"#6-6-1-交叉熵代价函数（Cross-entropy-Loss-Function）\" class=\"headerlink\" title=\"6.6.1 交叉熵代价函数（Cross-entropy Loss Function）\"></a>6.6.1 交叉熵代价函数（Cross-entropy Loss Function）</h3><p>当<strong>输出只有两种可能</strong>，即输出层神经元只有一个节点时，代价函数如下：</p>\n<p><img src=\"../img/fbce86409d601291b61f8d12423a676b.png\" alt=\"img\" style=\"zoom: 67%;\" /></p>\n<p>当<strong>输出有三种及以上</strong>种可能时，即输出层神经元有三个及以上节点时，（多分类问题），代价函数如下：</p>\n<p><img src=\"../img/屏幕截图 2024-08-09 111628.png\" alt=\"屏幕截图 2024-08-09 111628\"></p>\n<ul>\n<li>h(x)是一个K维向量</li>\n<li>K为输出的类别数，即输出层神经元的个数</li>\n<li>h(x)_i表示第i个输出 →i表示选择输出神经网络输出向量中的第i个元素</li>\n<li>正则化项分别对 j i l 求和，除去了偏置单元（i=0)</li>\n</ul>\n<p><img src=\"../img/image-20240809113613175.png\" alt=\"image-20240809113613175\" style=\"zoom: 67%;\" /></p>\n<h3 id=\"6-6-2-交叉熵代价函数-softmax函数\"><a href=\"#6-6-2-交叉熵代价函数-softmax函数\" class=\"headerlink\" title=\"6.6.2 交叉熵代价函数+ softmax函数\"></a>6.6.2 交叉熵代价函数+ softmax函数</h3><p><img src=\"../img/image-20240809132851079.png\" alt=\"image-20240809132851079\" style=\"zoom:67%;\" /></p>\n<p>代价函数公式：</p>\n<p><img src=\"../img/image-20240809132925966.png\" alt=\"image-20240809132925966\" style=\"zoom:67%;\" /></p>\n<h2 id=\"6-7-前向传播（Forward-Propagation）与反向传播（Back-Propagation，BP）\"><a href=\"#6-7-前向传播（Forward-Propagation）与反向传播（Back-Propagation，BP）\" class=\"headerlink\" title=\"6.7 前向传播（Forward Propagation）与反向传播（Back Propagation，BP）\"></a>6.7 前向传播（Forward Propagation）与反向传播（Back Propagation，BP）</h2><p>BP神经网络是一种多层的前馈神经网络，其主要的特点是：<strong>信号是前向传播的，而误差是反向传播的。</strong></p>\n<p><strong>正向传播</strong><br>数据（信息、信号）从输入端输入后，沿着网络的指向，乘以对应的权重后再加和，再将结果作为输入在激活函数中计算，将计算的结果作为输入传递给下一个节点。依次计算，直到得到最终结果。<br>通过每一层的感知器，层层计算，得到输出，每个节点的输出作为下一个节点的输入。这个过程就是正向传播。<br>                  <img src=\"../img/1ad8b1cfbef106772a65f91079230503.png\" alt=\"在这里插入图片描述\" style=\"zoom:67%;\" /></p>\n<p><strong>反向传播</strong><br>将输出的结果与期望的输出结果进行比较，将比较产生的误差利用网络进行反向传播，本质是一个“负反馈”的过程。通过多次迭代，不断地对网络上的各个节点间权重进行调整（更新），权重的调整（更新）采用梯度下降法。</p>\n<p><img src=\"../img/ab005f9adec9d8dc071334d10b4a2b39.png\" alt=\"在这里插入图片描述\" style=\"zoom:67%;\" /></p>\n<h3 id=\"6-7-1-BP算法的推导\"><a href=\"#6-7-1-BP算法的推导\" class=\"headerlink\" title=\"6.7.1 BP算法的推导\"></a>6.7.1 BP算法的推导</h3><p><a href=\"https://www.cnblogs.com/panchuangai/p/12567839.html\">一文彻底搞懂BP算法：原理推导+数据演示+项目实战（上篇） - 人工智能遇见磐创 - 博客园 (cnblogs.com)</a></p>\n<h2 id=\"6-8-独热编码（One-Hot-Encoding）\"><a href=\"#6-8-独热编码（One-Hot-Encoding）\" class=\"headerlink\" title=\"6.8 独热编码（One-Hot Encoding）\"></a>6.8 独热编码（One-Hot Encoding）</h2><p>one-hot编码，又称独热编码、一位有效编码。其方法是使用N位状态寄存器来对N个状态进行编码，每个状态都有它独立的寄存器位，并且在任意时间只有一位有效（标记为1），而其他所有特征都被标记为0。举个例子，假设我们有四个样本（行），每个样本有三个特征（列），如下图：</p>\n<p><img src=\"../img/5dd7aa71c35e8fa8110acc16b7881978.png\" alt=\"img\" style=\"zoom:67%;\" /></p>\n<p>我们拿feature2来说明：这里feature2有4种取值（状态），我们就用4个状态位来表示这个特征，one-hot编码就是保证每个样本中的单个特征只有1位处于状态1,其他的都是0。</p>\n<p><img src=\"../img/5fa4910fa7516b8826f3a9b335865ff0.png\" alt=\"在这里插入图片描述\" style=\"zoom:67%;\" /></p>\n<p>对于2种状态、3种状态、甚至更多状态都可以这样表示，所以我们可以得到这些样本特征的新表示：</p>\n<p><img src=\"../img/3a58f770438577bd09f54aba985ad9e9.png\" alt=\"img\" style=\"zoom:67%;\" /></p>\n<p>one-hot编码将每个状态位都看成一个特征。对于前两个样本我们可以得到它的特征向量分别为</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">Sample_1---&gt;[0,1,1,0,0,0,1,0,0]</span><br><span class=\"line\">Sample_2---&gt;[1,0,0,1,0,0,0,1,0]</span><br></pre></td></tr></table></figure>\n<p><strong>one-hot在提取文本特征上的应用</strong></p>\n<p>one hot在特征提取上属于词袋模型(bag of words)。关于如何使用one-hot抽取文本特征向量我们通过以下例子来说明。</p>\n<p>性别特征：[“男”,”女”]（N=2）：</p>\n<p>男  =&gt;  10</p>\n<p>女  =&gt;  01</p>\n<p>祖国特征：[“中国”，”美国，”法国”]（这里N=3）：</p>\n<p>中国  =&gt;  100</p>\n<p>美国  =&gt;  010</p>\n<p>法国  =&gt;  001</p>\n<p>运动特征：[“足球”，”篮球”，”羽毛球”，”乒乓球”]（这里N=4）：</p>\n<p>足球  =&gt;  1000</p>\n<p>篮球  =&gt;  0100</p>\n<p>羽毛球  =&gt;  0010</p>\n<p>乒乓球  =&gt;  0001</p>\n<p>所以，当一个样本为[“男”,”中国”,”乒乓球”]的时候，完整的特征数字化的结果为：</p>\n<p>[1，0，1，0，0，0，0，0，1]</p>\n<p><strong>独热编码的意义</strong></p>\n<p>在回归，分类，聚类等机器学习算法中，特征之间距离的计算或相似度的计算是非常重要的，而我们常用的距离或相似度的计算都是在欧式空间的相似度计算，计算余弦相似性，基于的就是欧式空间。</p>\n<p>为了使非偏序关系的变量取值不具有偏序性，并且到圆点是等距的。使用one-hot编码，将离散特征的取值扩展到了欧式空间，离散特征的某个取值就对应欧式空间的某个点。将离散型特征使用one-hot编码，会让特征之间的距离计算更加合理。离散特征进行one-hot编码后，编码后的特征，其实每一维度的特征都可以看做是连续的特征。就可以跟对连续型特征的归一化方法一样，对每一维特征进行归一化。比如归一化到[-1,1]或归一化到均值为0,方差为1。</p>\n<p>比如，有一个离散型特征，代表工作类型，该离散型特征，共有三个取值，不使用one-hot编码，其表示分别是x_1 = (1), x_2 = (2), x_3 = (3)。两个工作之间的距离是，(x_1, x_2) = 1, d(x_2, x_3) = 1, d(x_1, x_3) = 2。那么x_1和x_3工作之间就越不相似吗？显然这样的表示，计算出来的特征的距离是不合理。那如果使用one-hot编码，则得到x_1 = (1, 0, 0), x_2 = (0, 1, 0), x_3 = (0, 0, 1)，那么两个工作之间的距离就都是sqrt(2).即每两个工作之间的距离是一样的，显得更合理。<br><img src=\"../img/e8cbd761fc13ea931828f368c3418d2f.png\" alt=\"img\"></p>\n<p>但如果特征是离散的，并且不用one-hot编码就可以很合理的计算出距离，那么就没必要进行one-hot编码。 有些基于树的算法在处理变量时，并不是基于向量空间度量，数值只是个类别符号，即没有偏序关系，所以不用进行独热编码。 Tree Model不太需要one-hot编码： 对于决策树来说，one-hot的本质是增加树的深度。</p>\n<hr>\n<h1 id=\"七、误差分析与偏斜类的误差度量（Error-Analysis-and-Error-Metrics-for-Skewed-Classes）\"><a href=\"#七、误差分析与偏斜类的误差度量（Error-Analysis-and-Error-Metrics-for-Skewed-Classes）\" class=\"headerlink\" title=\"七、误差分析与偏斜类的误差度量（Error Analysis and Error Metrics for Skewed Classes）\"></a>七、误差分析与偏斜类的误差度量（Error Analysis and Error Metrics for Skewed Classes）</h1><p>所谓的偏斜类（Skewed Class）的问题，对于二元分类来说，其实就是一种分类的数据量远远大于另外一种分类。</p>\n<p>以是否恶性肿瘤（癌症）的分类为例，我们希望能根据病人的一些特征判断病人是否患有癌症（y=1表示有癌症，y=0表示没有癌症）。</p>\n<p>我们用逻辑回归算法来解决问题，发现在测试集有99%的正确率，这个结果看上去很完美。但是，你要知道患有癌症的毕竟是少数，可能在我们的测试集中只有0.5%的人真的患有癌症。这样的话，全部给预测为y=0（没有癌症），那也只有0.5%的错误。</p>\n<p><strong>混淆矩阵：</strong></p>\n<p><img src=\"../img/964f105db82a6985fe9f4a8a5e4c0a58.png\" alt=\"img\"></p>\n<p>　　</p>\n<p>我们将算法预测的结果分成四种情况：</p>\n<ol>\n<li>正确肯定（True Positive,TP）：预测为真，实际为真</li>\n<li>正确否定（True Negative,TN）：预测为假，实际为假</li>\n<li>错误肯定（False Positive,FP）：预测为真，实际为假</li>\n<li>错误否定（False Negative,FN）：预测为假，实际为真</li>\n</ol>\n<p><img src=\"../img/image-20240812110337759.png\" alt=\"image-20240812110337759\" style=\"zoom:67%;\" /></p>\n<p><strong>准确率</strong>（accuracy）</p>\n<p>所有预测正确的样本（包含正例或负例均预测正确，即正例预测为正TP或负例预测为负TN）占总样本的比例。</p>\n<p>准确率=(TP+TN)/(FP+FN+TN+TP)</p>\n<p><strong>查准率/精确率</strong>（Precision）</p>\n<p>查准率=TP/(TP+FP)。例，在所有我们预测有恶性肿瘤的病人中，实际上有恶性肿<br>瘤的病人的百分比，越高越好。</p>\n<p><strong>查全率/召回率</strong>（Recall）</p>\n<p>查全率=TP/(TP+FN)。例，在所有实际上有恶性肿瘤的病人中，成功预测有恶性肿瘤的<br>病人的百分比，越高越好。</p>\n<p><strong>P-R曲线：</strong></p>\n<p><img src=\"../img/38cb448ad97c1cbe951d904c721c3bff.png\" alt=\"img\"></p>\n<ul>\n<li><p>曲线越靠近右上方，性能越好。（例如上图黑色曲线）</p>\n</li>\n<li><p>当一个曲线被另一个曲线完全包含了，则后者性能优于前者。（例如橙蓝曲线，橙色优于蓝色）</p>\n</li>\n<li><p>如果曲线发生交叉（黑橙曲线），判断依据：</p>\n</li>\n</ul>\n<ol>\n<li><p>根据曲线下方面积大小判断，面积更大的更优于面积小的。</p>\n</li>\n<li><p>根据平衡点F判断：平衡点是查准率与查重率相等时的点。F计算公式为F = 2 <em> P </em> R ／( P +R )，F值    越大，性能越好。</p>\n</li>\n</ol>\n<p><strong>F1-score</strong></p>\n<p>精确率和召回率互相影响，理想状态下肯定追求两个都高，但是实际情况是两者相互“制约”：追求精确率高，则召回率就低；追求召回率高，则通常会影响精确率。我们当然希望预测的结果精确率越高越好，召回率越高越好， 但事实上这两者在某些情况下是矛盾的。这样就需要综合考虑它们，最常见的方法就是F-score。 也可以绘制出P-R曲线图，观察它们的分布情况。</p>\n<p>F1值为算数平均数除以几何平均数，且越大越好，将Precision和Recall的上述公式带入会发现，当F1值小时，True Positive相对增加，而false相对减少，即Precision和Recall都相对增加，即F1对Precision和Recall都进行了加权。</p>\n<p><img src=\"../img/image-20240812112114530.png\" alt=\"image-20240812112114530\" style=\"zoom:67%;\" /></p>\n<p><strong>ROC曲线</strong></p>\n<p>Receiver Operating Characteristic，“<strong>受试者工作特征曲线</strong>”，其主要分析工具是一个画在二维平面上的曲线——ROC 曲线。平面的横坐标是false positive rate(FPR)，纵坐标是true positive rate(TPR)。对某个分类器而言，我们可以根据其在<strong>测试样本上</strong>的表现得到一个<strong>TPR和FPR点对</strong>。这样，此分类器就可以映射成ROC平面上的一个点。调整这个分类器分类时候使用的阈值，我们就可以得到一个经过(0, 0)，(1, 1)的曲线，这就是此分类器的ROC曲线。     <strong>ROC 曲线距离基准线越远</strong>，则说明该模型的<strong>预测效果越好</strong>。</p>\n<p><img src=\"../img/cd9c1128997fb74ace9445b45ff210ef.png\" alt=\"img\" style=\"zoom:67%;\" /></p>\n<p>一般情况下，这个曲线都应该处于(0, 0)和(1, 1)<strong>连线的上方</strong>。因为(0, 0)和(1, 1)连线形成的ROC曲线实际上代表的是一个随机分类器。如果很不幸，你得到一个位于此直线下方的分类器的话，一个直观的补救办法就是把所有的预测结果反向，即：分类器输出结果为正类，则最终分类的结果为负类，反之，则为正类。虽然，用ROC曲线来表示分类器的性能很直观好用。可是，人们总是希望能有一个数值来标志分类器的好坏。于是Area Under roc Curve(AUC)就出现了。</p>\n<p>AUC的值就是处于ROC曲线下方的那部分面积的大小。通常，AUC的值介于0.5到1.0之间，较大的AUC代表了较好的性能。AUC（Area Under roc Curve）是一种用来度量分类模型好坏的一个标准。</p>\n<p><strong>从AUC判断分类器（预测模型）优劣的标准</strong></p>\n<p>· AUC = 1，是完美分类器，采用这个预测模型时，存在至少一个阈值能得出完美预测。绝大多数预测的场合，不存在完美分类器。</p>\n<p>· 0.5 &lt; AUC &lt; 1，优于随机猜测。这个分类器（模型）妥善设定阈值的话，能有预测价值。</p>\n<p>· AUC = 0.5，跟随机猜测一样（例：丢铜板），模型没有预测价值。</p>\n<p>· AUC &lt; 0.5，比随机猜测还差；但只要总是反预测而行，就优于随机猜测。</p>\n<hr>\n<h1 id=\"八、决策树（Decision-Tree）\"><a href=\"#八、决策树（Decision-Tree）\" class=\"headerlink\" title=\"八、决策树（Decision Tree）\"></a>八、决策树（Decision Tree）</h1><p>决策树是一种以树形数据结构来展示决策规则和分类结果的模型，又称为判定树，是数据挖掘技术中的一种重要的分类与回归方法。其重点是将看似无序、杂乱的已知数据，通过某种技术手段将它们转化成可以预测未知数据的树状模型。</p>\n<p>其每个非叶节点表示一个特征属性上的测试，每个分支代表这个特征属性在某个值域上的输出，而每个叶节点存放一个类别。每个内部结点视为一个条件，每对结点之间的有向边视为一个选项，每一条从根结点（对最终分类结果贡献最大的属性）到叶子结点（最终分类结果）的路径都代表一条决策的规则。</p>\n<p><img src=\"../img/5318f380a817ff7505e8c354d8dedfa0.png\" alt=\"img\"></p>\n<p><strong>决策树的组成</strong></p>\n<p>1、决策节点<br>通过条件判断而进行分支选择的节点。如：将某个样本中的属性值(特征值)与决策节点上的值进行比较，从而判断它的流向。</p>\n<p>2、叶子节点<br>没有子节点的节点，表示最终的决策结果。</p>\n<p><strong>决策树通常有三个步骤</strong>：</p>\n<p><strong>特征选择：</strong>选取有较强分类能力的特征。</p>\n<p><strong>决策树生成：</strong>典型的算法有 ID3 和 C4.5， 它们生成决策树过程相似， ID3 是采用信息增益作为特征选择度量， 而 C4.5 采用信息增益比率。</p>\n<p><strong>决策树剪枝：</strong>剪枝原因是决策树生成算法生成的树对训练数据的预测很准确， 但是对于未知数据分类很差， 这就产生了过拟合的现象。涉及算法有CART算法。</p>\n<ul>\n<li><p>决策树学习的目标：根据给定的训练数据集构建一个决策树模型，使它能够对实例进行正确的分类。并在损失函数的意义下，选择最优决策树的问题。</p>\n</li>\n<li><p>决策树学习的本质：从训练集中归纳出一组分类规则，或者说是由训练数据集估计条件概率模型。</p>\n</li>\n<li><p>决策树学习的损失函数：正则化的极大似然函数</p>\n</li>\n<li><p>决策树学习的测试：最小化损失函数</p>\n</li>\n</ul>\n<p><img src=\"../img/f155a644e51fa69492b0d2be723a9cd7.png\" alt=\"在这里插入图片描述\" style=\"zoom: 67%;\" /></p>\n<h2 id=\"8-1-熵\"><a href=\"#8-1-熵\" class=\"headerlink\" title=\"8.1 熵\"></a>8.1 熵</h2><p><strong>熵的作用</strong><br>熵（Entropy)是表示随机变量不确定性的度量。说简单点就是物体内部的混乱程度。比如下边的两幅图中，从 图1 到 图2 表示了熵增的过程。对于决策树的某个结点而言，它在对样本数据进行分类后，我们当然希望分类后的结果能使得整个样本集在各自的类别中尽可能有序，即希望某个特征在被用于分类后，能最大程度地降低样本数据的熵。</p>\n<p><img src=\"../img/3c1fb61fb983c8db1f83f1e09e2dfc0e.png#pic_center\" alt=\"在这里插入图片描述\" style=\"zoom: 33%;\" /></p>\n<p>现在假设有这样一个待分类数据（如下图所示），若分类器 1 选择特征 𝑥1、分类器 2 选择特征 𝑥2 分别为根构建了一棵决策树，其效果如下：</p>\n<p><img src=\"../img/2686120ddaba3cb64bc6ebf72363bd26.png#pic_center\" alt=\"在这里插入图片描述\" style=\"zoom: 25%;\" /></p>\n<p>则根据以上结果，可以很直观地认为，决策树 2 的分类效果优于决策树 1 。从熵的角度看，决策树 2 在通过特征 𝑥2 进行分类后，整个样本被划分为两个分别有序的类簇；而决策树 1 在通过特征 𝑥1 进行分类后，得到的分类结果依然混乱（甚至有熵增的情况），因此这个特征在现阶段被认为是无效特征。</p>\n<p><strong>熵的定义</strong></p>\n<p>构建决策树的实质是对特征进行层次选择，而衡量特征选择的合理性指标，则是熵。为便于说明，下面先给出熵的定义：设 𝑋 是取值在有限范围内的一个离散随机变量，其概率密度为：</p>\n<p><img src=\"../img/image-20240813110253335.png\" alt=\"image-20240813110253335\" style=\"zoom: 67%;\" /></p>\n<p><img src=\"../img/image-20240813110332426.png\" alt=\"image-20240813110332426\"></p>\n<p><img src=\"../img/屏幕截图 2024-08-13 110717.png\" alt=\"屏幕截图 2024-08-13 110717\"></p>\n<p><strong>条件熵的引入</strong></p>\n<p>在构建决策树时我们可采用一种很简单的思路来进行“熵减”：每当要选出一个内部结点时，考虑样本中的所有“尚未被使用”特征，并基于该特征的取值对样本数据进行划分。即有：</p>\n<p><img src=\"../img/f16a33b554d7199a519cb9adfa81ecd3.png#pic_center\" alt=\"在这里插入图片描述\"></p>\n<p>对于每个特征，都可以算出“该特征各项取值对运动会举办与否”的影响（而衡量各特征谁最合适的准则，即是熵）。为此，引入条件熵。首先看原始数据集 𝐷 （共14天）的熵，该数据的标签只有两个（“举办”与“不举办”），且各占一半，故可算出该数据集的初始熵为：</p>\n<p><img src=\"../img/image-20240813111745494.png\" alt=\"image-20240813111745494\" style=\"zoom:67%;\" /></p>\n<p>分析天气特征：</p>\n<p><img src=\"../img/image-20240813111816582.png\" alt=\"image-20240813111816582\"></p>\n<p><img src=\"../img/image-20240813111831106.png\" alt=\"image-20240813111831106\"></p>\n<p><strong>条件熵的计算</strong></p>\n<p><img src=\"../img/image-20240813112523217.png\" alt=\"image-20240813112523217\"></p>\n<h2 id=\"8-2-决策树的划分选择\"><a href=\"#8-2-决策树的划分选择\" class=\"headerlink\" title=\"8.2 决策树的划分选择\"></a>8.2 决策树的划分选择</h2><h3 id=\"信息增益（ID3决策树）\"><a href=\"#信息增益（ID3决策树）\" class=\"headerlink\" title=\"信息增益（ID3决策树）\"></a>信息增益（ID3决策树）</h3><p>表示某特征 𝑋 使得数据集 𝐷 的不确定性减少程度，定义为集合 𝐷 的熵与在给定特征 𝑋 的条件下 𝐷 的条件熵 𝐻(𝐷 | 𝑋) 之差</p>\n<p><img src=\"../img/image-20240813121702837.png\" alt=\"image-20240813121702837\"></p>\n<h3 id=\"信息增益率（C4-5决策树）\"><a href=\"#信息增益率（C4-5决策树）\" class=\"headerlink\" title=\"信息增益率（C4.5决策树）\"></a>信息增益率（C4.5决策树）</h3><p><img src=\"../img/image-20240813121852685.png\" alt=\"image-20240813121852685\"></p>\n<h3 id=\"基尼指数（CART决策树）\"><a href=\"#基尼指数（CART决策树）\" class=\"headerlink\" title=\"基尼指数（CART决策树）\"></a>基尼指数（CART决策树）</h3><p><img src=\"../img/image-20240813122040333.png\" alt=\"image-20240813122040333\"></p>\n<h3 id=\"三种算法的对比\"><a href=\"#三种算法的对比\" class=\"headerlink\" title=\"三种算法的对比\"></a>三种算法的对比</h3><p><strong>适用范围：</strong></p>\n<p>ID3算法只能处理离散特征的分类问题，C4.5能够处理离散特征和连续特征的分类问题，CART算法可以处理离散和连续特征的分类与回归问题。</p>\n<p><strong>假设空间：</strong></p>\n<p>ID3和C4.5算法使用的决策树可以是多分叉的，而CART算法的决策树必须是二叉树。</p>\n<p><strong>优化算法：</strong></p>\n<p>ID3算法没有剪枝策略，当叶子节点上的样本都属于同一个类别或者所有特征都使用过了的情况下决策树停止生长。</p>\n<p>C4.5算法使用预剪枝策略，当分裂后的增益小于给定阈值或者叶子上的样本数量小于某个阈值或者叶子节点数量达到限定值或者树的深度达到限定值，决策树停止生长。</p>\n<p>CART决策树主要使用后剪枝策略。</p>\n<h2 id=\"8-3-剪枝处理\"><a href=\"#8-3-剪枝处理\" class=\"headerlink\" title=\"8.3 剪枝处理\"></a>8.3 剪枝处理</h2><p>决策树会无休止的生长，直到训练样本中所有样本都被划分到正确的分类。实际上训练样本中含有异常点，当决策树节点样本越少的时候，异常点就可能使得该结点划分错误。另外，我们的样本属性并不一定能完全代表分类的标准，可能有漏掉的特征，也可能有不准确的特征。这样就会导致决策树在训练集上准确率超高，但是在测试集上效果不好，模型过拟合，泛化能力弱。因此我们需要适当控制决策树的生长。<br>剪枝处理是防止决策树过拟合的有效手段。剪枝，其实就是把决策树里不该生长的枝叶剪掉，也就是不该划分的节点就不要继续划分了。剪枝分为“预剪枝”和“后剪枝”。</p>\n<p><img src=\"../img/516563bb8f6ba2254c2ce27dfe7a9217.png\" alt=\"在这里插入图片描述\" style=\"zoom: 67%;\" /></p>\n<p><strong>预剪枝</strong></p>\n<p>在决策树生成过程中，对每个结点在划分前先进性估计，若当前结点的划分不能带来决策树泛化性能提升，则停止划分并将当前结点标记为叶结点。它的位置在每一次生成分支节点前，先判断有没有必要生成，如没有必要，则停止划分。</p>\n<p>预剪枝方法有：<br>（1）当叶节点的实例个数小于某个阈值时停止生长；<br>（2）当决策树达到预定高度时停止生长；<br>（3）当每次拓展对系统性能的增益小于某个阈值时停止生长；</p>\n<p><strong>限制决策树的深度</strong></p>\n<p>下图展示了通过限制树的深度以防止决策树出现过拟合风险的情况。</p>\n<p><img src=\"../img/image-20240813152353158.png\" alt=\"image-20240813152353158\" style=\"zoom:67%;\" /></p>\n<p><strong>限制决策树中叶子结点的个数</strong></p>\n<p>下图展示了通过限制决策树中叶子结点的个数以防止决策树出现过拟合风险的情况。</p>\n<p><img src=\"../img/image-20240813152410050.png\" alt=\"image-20240813152410050\" style=\"zoom:67%;\" /></p>\n<p><strong>限制决策树中叶子结点包含的样本个数</strong></p>\n<p>下图展示了通过限制决策树中叶子结点包含的样本个数以防止决策树出现过拟合风险的情况。</p>\n<p><img src=\"../img/image-20240813152632627.png\" alt=\"image-20240813152632627\"></p>\n<p><strong>限制决策树的最低信息增益</strong></p>\n<p>下图展示了通过限制决策树中叶子结点包含的样本个数以防止决策树出现过拟合风险的情况。</p>\n<p><img src=\"../img/image-20240813152857778.png\" alt=\"image-20240813152857778\"></p>\n<p><strong>后剪枝</strong></p>\n<p>先从训练集生成一棵完整的决策树（相当于结束位置），然后自底向上的对非叶结点进行考察，若将该结点对应的子树替换为叶结点能带来决策树泛化性能提升，则将该子树替换为叶结点，相当于将子树剪去。如果剪掉该节点，带来的验证集中准确性差别不大或有明显提升，则可以对它进行剪枝，用叶子节点来代填该节点。</p>\n<p>值得注意的是，后剪枝时要用到一个测试数据集合，如果存在某个叶子剪去后能使得在测试集上的准确度或其他测度不降低（不变得更坏），则剪去该叶子。</p>\n<p>后剪枝决策树通常比预剪枝决策树保留了更多的分枝，一般情形下，后剪枝决策树的欠拟合风险很小，泛化能力往往优于预剪枝决策树。但后剪枝决策树是在生产完全决策树之后进行的，并且要自底向上地对所有非叶子节点进行逐一考察，因此其训练时间开销比未剪枝的决策树和预剪枝的决策树都要大很多。</p>\n<h2 id=\"8-4-连续与缺失值\"><a href=\"#8-4-连续与缺失值\" class=\"headerlink\" title=\"8.4 连续与缺失值\"></a>8.4 连续与缺失值</h2><p><strong>连续值处理</strong></p>\n<p>（1）提出原因</p>\n<p>看看我们上面的例子，有些属性取值是离散的，有些是连续的。连续属性的可取值数目不是有限的，所以不能直接根据连续属性的可取值来对节点进行划分。</p>\n<p>（2）做法——连续属性离散化技术</p>\n<p>最简单的方法是二分法。</p>\n<p><img src=\"../img/image-20240813145855856.png\" alt=\"image-20240813145855856\"></p>\n<p><strong>缺失值处理</strong></p>\n<p>（1）提出原因</p>\n<p>在样本获得的过程中，难免会因某些原因致使最后拿到的样本集出现某些属性数据的缺失。</p>\n<p>（2）做法</p>\n<p>当缺失的数据非常少时，一般直接舍弃掉那些缺失的数据；而当缺失的数据较多时，简单舍弃则是对样本的极大浪费，则按照一定的方法进行处理。</p>\n<p>当缺失的数据较多时，对信息增益的计算公式进行修改：</p>\n<p><img src=\"../img/image-20240813170942213.png\" alt=\"image-20240813170942213\" style=\"zoom:67%;\" /></p>\n<p><img src=\"../img/image-20240813171012837.png\" alt=\"image-20240813171012837\"></p>\n<h2 id=\"8-5-回归树（regression-tree）\"><a href=\"#8-5-回归树（regression-tree）\" class=\"headerlink\" title=\"8.5 回归树（regression tree）\"></a>8.5 回归树（regression tree）</h2><p>常用的决策树有 ID3、C4.5、CART 等，其中 CART 就可以用来做回归问题，CART 全称就是 Classification And Regression Tree（分类和回归树）。</p>\n<p>回归树（regression tree）就是用树模型做回归问题，每一片叶子都输出一个预测值。预测值一般是该片叶子所含训练集元素输出的均值，即</p>\n<p><img src=\"../img/image-20240814114247934.png\" alt=\"image-20240814114247934\" style=\"zoom:67%;\" /></p>\n<p>CART 在分类问题和回归问题中的相同和差异：</p>\n<ul>\n<li>相同：<ul>\n<li>在分类问题和回归问题中，CART 都是一棵二叉树，除叶子节点外的所有节点都有且仅有两个子节点；</li>\n<li>所有落在同一片叶子中的输入都有同样的输出。</li>\n</ul>\n</li>\n<li>差异：<ul>\n<li>在分类问题中，CART 使用基尼指数（Gini index）作为选择特征（feature）和划分（split）的依据；在回归问题中，CART 使用 mse（mean square error）或者 mae（mean absolute error）作为选择 feature 和 split 的 criteria。</li>\n<li>在分类问题中，CART 的每一片叶子都代表的是一个 class；在回归问题中，CART 的每一片叶子表示的是一个预测值，取值是连续的。</li>\n</ul>\n</li>\n</ul>\n<p>下面以 criteria = ‘mse’ 为例，介绍 CART 回归树。</p>\n<p><img src=\"../img/image-20240814115354424.png\" alt=\"image-20240814115354424\"></p>\n<p><img src=\"../img/image-20240814115521073.png\" alt=\"image-20240814115521073\"></p>\n<h2 id=\"8-6-随机森林（Random-Forest，RF）\"><a href=\"#8-6-随机森林（Random-Forest，RF）\" class=\"headerlink\" title=\"8.6 随机森林（Random Forest，RF）\"></a>8.6 随机森林（Random Forest，RF）</h2><p>随机森林是一个由许多决策树组成的集成模型。它的核心思路是，当训练数据被输入模型时，随机森林并不是用整个训练数据集建立一个大的决策树，而是采用不同的子集和特征属性建立多个小的决策树，然后将它们合并成一个更强大的模型。通过对多个决策树的结果进行组合，随机森林可以增强模型的效果。</p>\n<p>另一个随机森林的重要特点是，每个子集都是通过随机选择的样本和随机选择的特征属性建立的。这种随机化可以减少决策树对训练数据的敏感性，从而防止过拟合。</p>\n<p>随机森林的可视化结构图如下：</p>\n<p><img src=\"../img/894e5726784de21d1259b96f2489ee2d.jpeg\" alt=\"请添加图片描述\"></p>\n<p>除叶子节点外，所有节点都有5个部分：</p>\n<p> ● 基于某个特征的一个值对数据进行的提问，每个提问都有一个真或假的答案可以分裂节点。根据答案，数据点相应地向下移动。<br> <strong>● gini：</strong> 节点的Gini不纯度。当我们沿着树向下移动时，平均加权基尼不纯度会减少。<br> <strong>● samples</strong> ：节点中的观测数据数量。<br> <strong>● value：</strong> 每个类中的样本数。例如，根节点中有2个样本属于类0，有4个样本属于类1。<br> <strong>● class：</strong> 该节点中大多数点的分类。在叶节点中，即是对节点中所有样本的预测。</p>\n<p>叶节点中不再提问，因为这里已经产生了最终的预测。要对某个新数据点进行分类，只需沿着树向下移动，使用新点的特征来回答问题，直到到达某个叶节点，该叶节点对应的分类就是最终的预测。</p>\n<h3 id=\"8-6-1-转换器（transformer）和估计器（estimator）\"><a href=\"#8-6-1-转换器（transformer）和估计器（estimator）\" class=\"headerlink\" title=\"8.6.1 转换器（transformer）和估计器（estimator）\"></a>8.6.1 转换器（transformer）和估计器（estimator）</h3><p>Scikit-learn (sklearn)中两个重要的概念是转换器（transformer）和估计器（estimator）</p>\n<p><strong>转换器</strong></p>\n<p>转换器是将数据集从一种形式转换为另一种形式的工具。例如，将原始数据进行标准化处理，将文本数据转换为数值特征等。在sklearn中，转换器类的名称以Transformer结尾。转换器通常有一个fit_transform()方法，可以在训练集上拟合模型并将其应用于测试集。</p>\n<p><strong>特征工程的步骤</strong></p>\n<ol>\n<li><p>实例化（实例化是一个转换器类（Transformer））</p>\n</li>\n<li><p>调用fit_tranformer(对于文档建立分类词频矩阵)</p>\n</li>\n</ol>\n<p><strong>我们把特征工程的接口称之为转换器，其中转换器调用有这么几种形式：</strong></p>\n<ul>\n<li>fit_transform</li>\n<li>fit 计算每列的平均值与标准差</li>\n<li>transform 进行最终的标准化</li>\n</ul>\n<p><strong>常见的转换器：</strong></p>\n<p>StandardScaler：用于标准化数值特征。<br>OneHotEncoder：用于将分类变量转换为数值特征。<br>CountVectorizer：用于将文本数据转换为数值特征。<br>PCA：用于将高维数据集降低维度。</p>\n<p><strong>估计器</strong><br>在sklearn中，估计器（estimator）是一个重要角色，分类器和回归器都属于estimator，是一类实现了算法的API。</p>\n<p>估计器是一种从数据集中学习模型的工具。估计器的任务是使用拟合模型对新数据进行预测。在sklearn中，估计器类的名称以Estimator结尾。估计器有两个基本方法，fit()方法和predict()方法。fit()方法在训练集上训练模型，而predict()方法用于在新数据上进行预测。</p>\n<p>需要注意的是，某些转换器也可以作为估计器使用，这意味着它们可以使用fit()方法在训练集上拟合模型，并使用predict()方法对新数据进行预测。这些转换器估计器也被称为“带监督的转换器”。</p>\n<p><strong>用于分类的估计器</strong></p>\n<p>sklearn.neighbors                                        k-近邻算法<br>sklearn.native_bayes                                   贝叶斯<br>sklearn.linear_model.LogisticRegression 逻辑回归<br>sklearn.tree                                                   决策树与随机森林</p>\n<p><strong>用于回归估计器</strong></p>\n<p>sklearn.linear_model.LinearRegression    线性回归<br>sklearn.linear_model.Ridge                         岭回归</p>\n<p><strong>用于无监督学习的估计器</strong></p>\n<p>sklearn.cluster.KMeans 聚类</p>\n<p><strong>估计器的流程</strong></p>\n<p>数据划分为训练集和测试集，我们建立模型的时候只需要把训练集输入进去就可以。训练集包括x_train、y_train,调用fit传入x_train、y_train,这样此算法就能利用这个模型进行计算，模型建立好之后要预测数据，看模型预测的数据准确与否，输入测试集的数据x_test、y_test,调用predict(x_test)，把测试集的特征值输入进去，来预测此测试集的目标值是什么（就像把特征值输入进去预测房价走向），每个算法应该都包括score这个方法，查看预测的准确性score(x_test,y_test)，真实值是1类别，预测值是2类别，就视为不准确。预测的时候应该有预测的类别和真实的类别。</p>\n<p>1.实例化一个estimator类</p>\n<p>2.estimator.fit(x_train,y_train) 计算</p>\n<p> ——调用完毕，模型生成</p>\n<p>3.模型评估</p>\n<p>1）直接比对真实值和预测值</p>\n<p> y_predict = estimator.predict(x_test)</p>\n<p> y_test == y_predict</p>\n<p>2）计算准确率</p>\n<p> accuracy = estimator.score(x_test,y_test)</p>\n<p><img src=\"../img/fa19712bc863e4e1f0c08ece26a43ae5.png\" alt=\"img\"></p>\n<h3 id=\"8-6-2-集成学习\"><a href=\"#8-6-2-集成学习\" class=\"headerlink\" title=\"8.6.2 集成学习\"></a>8.6.2 集成学习</h3><p>集成学习通过训练学习出多个估计器，当需要预测时通过结合器将多个估计器的结果整合起来当作最后的结果输出。集成学习的优势是提升了单个估计器的通用性与鲁棒性，比单个估计器拥有更好的预测性能。集成学习的另一个特点是能方便的进行并行化操作。</p>\n<p><img src=\"../img/c12e586cb823f30a77ebdf3fc3bae1c9.png\" alt=\"0.png\"></p>\n<p><strong>Bagging算法</strong><br>  Bagging 算法是一种集成学习算法，其全称为自助聚集算法（Bootstrap aggregating），顾名思义算法由 Bootstrap 与 Aggregating 两部分组成。<br>  图展示了Bagging 算法使用自助取样（Bootstrapping4）生成多个子数据的示例<br><img src=\"../img/1086acbf613ccf40deec32d5f6e616de.png\" alt=\"1.png\"></p>\n<p><strong>具体生成规则：</strong></p>\n<p>在随机森林算法中，为了增强模型的多样性和避免过拟合，每棵决策树在拆分节点时只使用所有特征的一个随机子集。对于分类任务，通常会选择特征总数的平方根（sqrt(n_features)）作为子集的大小。例如，如果有16个特征，每个节点的拆分将只考虑4个特征。这个设置可以通过Scikit-Learn中的参数来调整，也可以选择使用全部特征进行拆分，特别是在回归问题中。</p>\n<p>假设有一个大小为 N 的训练数据集，每次从该数据集中有放回的取选出大小为 M 的子数据集，一共选 K 次，根据这 K 个子数据集，训练学习出 K 个模型。当要预测的时候，使用这 K 个模型进行预测，再通过取平均值或者多数分类的方式，得到最后的预测结果。</p>\n<p>　　1）如果训练集大小为N，对于每棵树而言，随机且有放回地从训练集中的抽取N个训练样本（这种采样方式称为bootstrap sample方法），作为该树的训练集；每棵树的训练集都是不同的，而且里面包含重复的训练样本。</p>\n<p>在训练时，随机森林中的每棵树都会从数据点的随机样本中学习。样本被有放回的抽样，称为自助抽样法（bootstrapping），这意味着一些样本将在一棵树中被多次使用。背后的想法是在不同样本上训练每棵树，尽管每棵树相对于特定训练数据集可能具有高方差，但总体而言，整个森林将具有较低的方差，同时不以增加偏差为代价。</p>\n<p>　　2）如果每个样本的特征维度为M，指定一个常数m&lt;&lt;M，随机地从M个特征中选取m个特征子集，每次树进行分裂时，从这m个特征中选择最优的；</p>\n<p>　　3）每棵树都尽最大程度的生长，并且没有剪枝过程。</p>\n<p>　随机森林中的“随机”就是指的这里的随机性。随机性的引入对随机森林的分类性能至关重要。由于它们的引入，使得随机森林不容易陷入过拟合，并且具有很好得抗噪能力（比如：对缺省值不敏感）。</p>\n<p><strong>随机森林算法</strong>将多个决策树结合在一起，每次数据集是随机有放回的选出，同时随机选出部分特征作为输入，所以该算法被称为随机森林算法。可以看到随机森林算法是以决策树为估计器的Bagging算法。</p>\n<p><img src=\"../img/b94d67cbf2f588dd06efcc15271ee369.png\" alt=\"2.png\"></p>\n<p>结合器在分类问题中，选择多数分类结果作为最后的结果，在回归问题中，对多个回归结果取平均值作为最后的结果。使用Bagging算法能降低过拟合的情况，从而带来了更好的性能。单个决策树对训练集的噪声非常敏感，但通过Bagging算法降低了训练出的多颗决策树之间关联性，有效缓解了上述问题。</p>\n<p><strong>随机森林分类效果（错误率）与两个因素有关：</strong></p>\n<p>森林中任意两棵树的相关性：相关性越大，错误率越大；<br>森林中每棵树的分类能力：每棵树的分类能力越强，整个森林的错误率越低。<br>减小特征选择个数m，树的相关性和分类能力也会相应的降低；增大m，两者也会随之增大。所以关键问题是如何选择最优的m（或者是范围），这也是随机森林唯一的一个参数。</p>\n<p>RF在可解释性上不能同传统决策树相提并论，但是它的一大优势是不用太关注选择好的超参数。RF相比单个决策树，对噪声或者异常值十分具有鲁棒性，因而RF通常亦不需要剪枝。在实践中唯一需要关心的参数就是the number of trees: n。n越大，RF分类器的性能越好，同时其计算代价也越大。</p>\n<p>当然，如果需要，像bootstrap sample的采样数m，以及再每次split时随机选取的属性子集的数目d，这些超参数也是可以优化的。可以通过这些参数来控制RF的bias-variance trade-off。</p>\n<ul>\n<li>属性子集d，越小，个体树的性能有所降低，但整个RF模型会越健壮。d越大，属性随机性会降低，容易过拟合。</li>\n<li>减小采样数m，能增加个体树之间的多样性，因为一个样本被包含在bootstrap sample里的概率变小了。所以减小m可以增加RF的随机性，这将有助于降低过拟合风险。然而，更小的m将会使得RF的整体性能降低，使得training和test 性能之间的有小的gap，有更低的test performance。相反的，增大m会引起一定程度的过拟合，因为bootstrap sample以及后续的个体决策树会变得彼此更相似，他们会更加接近的学习拟合原始训练数据集。</li>\n</ul>\n<h2 id=\"8-7-XGBoost（eXtreme-Gradient-Boosting）\"><a href=\"#8-7-XGBoost（eXtreme-Gradient-Boosting）\" class=\"headerlink\" title=\"8.7 XGBoost（eXtreme Gradient Boosting）\"></a>8.7 XGBoost（eXtreme Gradient Boosting）</h2><p>XGBoost全称为eXtreme Gradient Boosting，即极致梯度提升树。</p>\n<p>XGBoost是Boosting算法的其中一种，Boosting算法的思想是将许多弱分类器集成在一起，形成一个强分类器（个体学习器间存在强依赖关系，必须串行生成的序列化方法）。XGBoost是由多棵CART(Classification And Regression Tree)，即分类回归树组成，因此他可以处理分类回归等问题。</p>\n<p><strong>整体思路</strong></p>\n<p>（1）训练过程——构建XGBoost模型       </p>\n<p>​       从目标函数出发，可以推导出“每个叶子节点应该赋予的权值”，”分裂节点后的信息增益“，以及”特征值重要性排序函数“。</p>\n<p>  与决策树的建立方法类似。当前决策树的建立首先根据贪心算法进行划分，通过计算目标函数增益（及上面所说的”分裂节点后的信息增益“），选择该结点使用哪个特征。</p>\n<p>   选择好哪个特征后，就要确定分左右子树的条件了（比如选择特征A，条件是A&lt;7）：为了提高算法效率（不用一个一个特征值去试），使用“加权分位法”，计算分裂点（这里由”特征值重要性排序函数“得出分裂点）。</p>\n<p>  并且对应叶子节点的权值就由上述的“每个叶子节点应该赋予的权值”给出。</p>\n<p>  不断进行上述算法，直至所有特征都被使用或者已经达到限定的层数，则完整的决策树构建完成。</p>\n<p>（2）测试过程<br>      将输入的特征，依次输入进XGBoost的每棵决策树。每棵决策树的相应节点都有对应的预测权值w，将“在每一棵决策树中的预测权值”全部相加，即得到最后预测结果，看谁大，谁大谁是最后的预测结果。</p>\n<p><a href=\"https://blog.csdn.net/weixin_44852067/article/details/130346159?ops_request_misc=%7B%22request%5Fid%22%3A%22172371047816800178553268%22%2C%22scm%22%3A%2220140713.130102334..%22%7D&amp;request_id=172371047816800178553268&amp;biz_id=0&amp;utm_medium=distribute.pc_search_result.none-task-blog-2~all~top_click~default-5-130346159-null-null.142^v100^pc_search_result_base2&amp;utm_term=xgboost算法&amp;spm=1018.2226.3001.4187\">XGBoost模型详解-CSDN博客</a></p>\n<p><a href=\"https://blog.csdn.net/weixin_39910711/article/details/121210569?ops_request_misc=&amp;request_id=&amp;biz_id=102&amp;utm_term=xgboost算法&amp;utm_medium=distribute.pc_search_result.none-task-blog-2~all~sobaiduweb~default-3-121210569.142^v100^pc_search_result_base2&amp;spm=1018.2226.3001.4187\">机器学习算法（十五）：XGBoost_xgboost回归-CSDN博客</a></p>\n<hr>\n<h1 id=\"九、支持向量机（SVM，support-vector-machines）\"><a href=\"#九、支持向量机（SVM，support-vector-machines）\" class=\"headerlink\" title=\"九、支持向量机（SVM，support vector machines）\"></a>九、支持向量机（SVM，support vector machines）</h1><p><strong>超平面的数学表示</strong><br>在二维空间中，一个直线可以表示为 ( ax + by + c = 0 )。其中，向量 (a, b) 就是这条直线的法向量，指向垂直于直线的方向。</p>\n<p>在更高维度，比如三维空间，一个平面可以用方程 ( ax + by + cz + d = 0 ) 来描述，这里 ( a, b, c ) 是这个平面的法向量。</p>\n<p><strong>神经网络试图学习决策边界，最小化经验误差，而支持向量机试图学习决策边界，最大化决策边界和数据点之间的经验边际。</strong></p>\n<p>与Logistic Regression相比，SVM是一种优化的分类算法，其动机是寻找一个最佳的决策边界（超平面），能够将两个不同类别的样本划分开来，使得从决策边界与各组数据之间存在<strong>margin</strong>，并且需要使各侧的margin最大化。比较容易理解的是，从决策边界到各个training example的距离越大，在分类操作的差错率就会越小。因此，SVM也叫作Large Margin Classifier。</p>\n<p><img src=\"../img/4a7811c5ab39c0ef2fa326798787732b.png\" alt=\"img\" style=\"zoom: 50%;\" /></p>\n<ul>\n<li>分割超平面：将上述数据集分隔开来的直线成为分隔超平面。对于二维平面来说，分隔超平面就是一条直线。对于三维及三维以上的数据来说，分隔数据的是个平面，称为超平面，也就是分类的决策边界。</li>\n<li>间隔：点到分割面的距离，称为点相对于分割面的间隔。数据集所有点到分隔面的最小间隔的2倍，称为分类器或数据集的间隔。论文中提到的间隔多指这个间隔。SVM分类器就是要找最大的数据集间隔。</li>\n<li>支持向量：离分隔超平面最近的那些点。</li>\n</ul>\n<p><strong>目标函数：</strong></p>\n<p><img src=\"../img/23c0c2152121614d3083c881a156d978.png\" alt=\"在这里插入图片描述\" style=\"zoom:67%;\" /></p>\n<p><strong>支持向量机只考虑局部的边界线附近的点，而逻辑回归考虑全局</strong></p>\n<p>线性SVM不直接依赖于数据分布，分类平面不受一类点影响，影响SVM决策面的样本点只有少数的结构支持向量，当在支持向量外添加或减少任何样本点对分类决策面没有任何影响；而在LR中，每个样本点都会影响决策面的结果如果数据不同类别strongly unbalance，一般需要先对数据做balancing。用下图进行说明：</p>\n<p><strong>支持向量机改变非支持向量样本并不会引起决策面的变化：</strong><br><img src=\"../img/eb7fc04015adf5980e9095e9dc3b89bb.png\" alt=\"在这里插入图片描述\" style=\"zoom: 50%;\" /></p>\n<p><strong>逻辑回归中改变任何样本都会引起决策面的变化：</strong><br><img src=\"../img/5e14592ddd891d8016a1ff359ecb39f7.png\" alt=\"在这里插入图片描述\" style=\"zoom:50%;\" /></p>\n<p><a href=\"https://blog.csdn.net/lsb2002/article/details/131338700?ops_request_misc=%7B%22request%5Fid%22%3A%22172241166216800227465674%22%2C%22scm%22%3A%2220140713.130102334..%22%7D&amp;request_id=172241166216800227465674&amp;biz_id=0&amp;utm_medium=distribute.pc_search_result.none-task-blog-2~all~top_positive~default-2-131338700-null-null.142^v100^pc_search_result_base2&amp;utm_term=svm&amp;spm=1018.2226.3001.4187\">机器学习之支持向量机（SVM）-CSDN博客</a></p>\n<p><a href=\"https://blog.csdn.net/macyang/article/details/38782399\">支持向量机通俗导论（理解SVM的三层境界）-CSDN博客</a></p>\n<p><a href=\"https://blog.csdn.net/qq_22841387/article/details/138164031\">机器学习：深入解析SVM的核心概念【一、间隔与支持向量】_svm最小间隔是什么意思-CSDN博客</a></p>\n<p><strong>核函数</strong></p>\n<p><a href=\"https://blog.csdn.net/kateyabc/article/details/79980880?ops_request_misc=&amp;request_id=&amp;biz_id=102&amp;utm_term=核函数&amp;utm_medium=distribute.pc_search_result.none-task-blog-2~all~sobaiduweb~default-4-79980880.142^v100^pc_search_result_base2&amp;spm=1018.2226.3001.4187\">核函数详解-CSDN博客</a></p>\n<p><a href=\"https://www.cnblogs.com/xingshansi/p/6767980.html\">统计学习方法：核函数（Kernel function） - LeeLIn。 - 博客园 (cnblogs.com)</a></p>\n<p><a href=\"https://blog.csdn.net/weixin_44492824/article/details/122546701?ops_request_misc=%7B%22request%5Fid%22%3A%22172344102816800227477740%22%2C%22scm%22%3A%2220140713.130102334.pc%5Fall.%22%7D&amp;request_id=172344102816800227477740&amp;biz_id=0&amp;utm_medium=distribute.pc_search_result.none-task-blog-2~all~first_rank_ecpm_v1~rank_v31_ecpm-15-122546701-null-null.142^v100^pc_search_result_base2&amp;utm_term=核函数&amp;spm=1018.2226.3001.4187\">核函数 高斯核函数，线性核函数，多项式核函数-CSDN博客</a></p>\n<h1 id=\"十、无监督学习\"><a href=\"#十、无监督学习\" class=\"headerlink\" title=\"十、无监督学习\"></a>十、无监督学习</h1><ol>\n<li>监督学习是一种目的明确的训练方式，你知道得到的是什么；而<strong>无监督学习则是没有明确目的的训练方式，你无法提前知道结果是什么</strong>。</li>\n<li>监督学习需要给数据打标签；而<strong>无监督学习不需要给数据打标签</strong>。</li>\n<li>监督学习由于目标明确，所以可以衡量效果；而<strong>无监督学习几乎无法量化效果如何</strong>。</li>\n</ol>\n<div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th><strong>聚类方法</strong></th>\n<th><strong>适用场景</strong></th>\n<th><strong>代表算法</strong></th>\n<th><strong>优点</strong></th>\n<th><strong>缺陷</strong></th>\n<th><strong>延伸</strong></th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>层次聚类</td>\n<td>小样本数据</td>\n<td></td>\n<td>可以形成类相似度层次图谱，便于直观的确定类之间的划分。</td>\n<td>难以处理大量样本</td>\n<td></td>\n</tr>\n<tr>\n<td>基于划分的聚类</td>\n<td>大样本数据</td>\n<td>K-means算法</td>\n<td>-是解决聚类问题的一种经典算法，简单、快速，复杂度为O(N)                      -对处理大数据集，该算法保持可伸缩性和高效率                                    -当簇近似为高斯分布时，它的效果较好</td>\n<td>-在簇的平均值可被定义的情况下才能使用，可能不适用于某些应用                                 -必须事先给出k(要生成的簇的数目)，而且对初值敏感，对于不同的初始值，可能会导致不同结果。       -不适合于发现非凸形状的簇或者大小差别很大的簇                                     -对躁声和孤立点数据敏感</td>\n<td>-可作为其他聚类方法的基础算法，如谱聚类                     -k值可以通过其他的算法来估计，如：BIC(Bayesian information criterion)、MDL(minimum description length)</td>\n</tr>\n<tr>\n<td>两步法聚类</td>\n<td>大样本数据</td>\n<td>BIRCH算法</td>\n<td>层次法和k-means法的结合，具有运算速度快、不需要大量递归运算、节省存储空间的优点</td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td>基于密度的聚类</td>\n<td>大样本数据</td>\n<td>DBSCAN算法</td>\n<td>基于密度定义，相对抗噪音，能处理任意形状和大小的簇。 无需指定聚类数量，对数据的先验要求不高。</td>\n<td>当簇的密度变化太大时，会有麻烦对于高维问题，密度定义是个比较麻烦的问题</td>\n</tr>\n</tbody>\n</table>\n</div>\n<h2 id=\"10-1-k-means聚类算法-K-means-clustering\"><a href=\"#10-1-k-means聚类算法-K-means-clustering\" class=\"headerlink\" title=\"10.1 k-means聚类算法(K-means clustering)\"></a>10.1 k-means聚类算法(K-means clustering)</h2><p>与分类、序列标注等任务不同，聚类是在事先并不知道任何样本标签的情况下，通过数据之间的内在关系把样本划分为若干类别，使得同类别样本之间的相似度高，不同类别之间的样本相似度低（即增大类内聚，减少类间距）。</p>\n<p> <strong>K-means 的著名解释：牧师—村民模型</strong><br>（1）有四个牧师去郊区布道，一开始牧师们随意选了几个布道点，并且把这几个布道点的情况公告给了郊区所有的村民，于是每个村民到离自己家最近的布道点去听课。</p>\n<p>（2）听课之后，大家觉得距离太远了，于是每个牧师统计了一下自己的课上所有的村民的地址，搬到了所有地址的中心地带，并且在海报上更新了自己的布道点的位置。</p>\n<p>（3）牧师每一次移动不可能离所有人都更近，有的人发现A牧师移动以后自己还不如去B牧师处听课更近，于是每个村民又去了离自己最近的布道点……</p>\n<p>（4）就这样，牧师每个礼拜更新自己的位置，村民根据自己的情况选择布道点，最终稳定了下来。</p>\n<p><strong>K-Means算法的思想</strong></p>\n<p>对于给定的样本集，按照样本之间的距离大小，将样本集划分为K个簇。让簇内的点尽量紧密的连在一起，而让簇间的距离尽量的大。</p>\n<p><img src=\"../img/image-20240819102414335.png\" alt=\"image-20240819102414335\" style=\"zoom:67%;\" /></p>\n<p><img src=\"../img/1042406-20161212135954464-1143551568.png\" alt=\"img\"></p>\n<p>上图a表达了初始的数据集，假设k=2。在图b中，我们随机选择了两个k类所对应的类别质心，即图中的红色质心和蓝色质心，然后分别求样本中所有点到这两个质心的距离，并标记每个样本的类别为和该样本距离最小的质心的类别，如图c所示，经过计算样本和红色质心和蓝色质心的距离，我们得到了所有样本点的第一轮迭代后的类别。此时我们对我们当前标记为红色和蓝色的点分别求其新的质心，如图4所示，新的红色质心和蓝色质心的位置已经发生了变动。图e和图f重复了我们在图c和图d的过程，即将所有点的类别标记为距离最近的质心的类别并求新的质心。最终我们得到的两个类别如图f。</p>\n<p>当然在实际K-Mean算法中，我们一般会多次运行图c和图d，才能达到最终的比较优的类别。</p>\n<p><strong>K-Means 算法 步骤</strong></p>\n<p>给定数据集  X , 该数据集有  n 个样本 , 将其分成  K 个聚类 ;</p>\n<p>① 中心点初始化 : 为 K 个聚类分组选择初始的中心点 , 这些中心点称为 Means ; 可以依据经验 , 也可以随意选择 ;</p>\n<p>② 计算距离 : 计算  n 个对象与  K 个中心点 的距离 ; ( 共计算  n×K 次 )</p>\n<p>③ 聚类分组 : 每个对象与 K 个中心点的值已计算出 , 将每个对象分配给距离其最近的中心点对应的聚类 ;</p>\n<p>④ 计算中心点 : 根据聚类分组中的样本 , 计算每个聚类的中心点 ;</p>\n<p>⑤ 迭代直至收敛 : 迭代执行 ② ③ ④ 步骤 , 直到新计算出来的质心和原来的质心之间的距离小于某一个设置的阈值（聚类算法收敛）, 即中心点和分组经过多少次迭代都不再改变 , 也就是本次计算的中心点与上一次的中心点一样 </p>\n<p><img src=\"../img/image-20240819103725374.png\" alt=\"image-20240819103725374\"></p>\n<p><a href=\"https://blog.csdn.net/u014361280/article/details/131547468?ops_request_misc=&amp;request_id=&amp;biz_id=102&amp;utm_term=k-means&amp;utm_medium=distribute.pc_search_result.none-task-blog-2~all~sobaiduweb~default-2-131547468.142^v100^pc_search_result_base2&amp;spm=1018.2226.3001.4187\">【海量数据挖掘/数据分析】之 K-Means 算法（K-Means算法、K-Means 中心值计算、K-Means 距离计算公式、K-Means 算法迭代步骤、K-Means算法实例）_kmeans聚类算法-CSDN博客</a></p>\n<p><strong>K-Means的K值选择</strong></p>\n<p>K 值的选取对 K-means 影响很大，这也是 K-means 最大的缺点，常见的选取 K 值的方法有：手肘法、Gap statistic 方法。</p>\n<p>（1）手肘法</p>\n<ul>\n<li>核心指标：SSE(sum of the squared errors，误差平方和), SSE值越小表示数据点越接近他们的质心，聚类效果也最好。因为对误差取了平方，因此更加重视远离中心的点。</li>\n<li>核心思想</li>\n</ul>\n<p>随着聚类数k的增大，样本划分会更加精细，每个簇的聚合程度会逐渐提高，那么误差平方和SSE自然会逐渐变小。<br>当k小于真实聚类数时，由于k的增大会大幅增加每个簇的聚合程度，故SSE的下降幅度会很大，而当k到达真实聚类数时，再增加k所得到的聚合程度回报会迅速变小，所以SSE的下降幅度会骤减，然后随着k值的继续增大而趋于平缓，也就是说SSE和k的关系图是一个手肘的形状，而这个肘部对应的k值就是数据的真实聚类数<br><img src=\"../img/620ef8567f313fa1ae0913f7c18648c0.png\" alt=\"img\"></p>\n<p>显然，肘部对于的k值为3(曲率最高)，故对于这个数据集的聚类而言，最佳聚类数应该选3。</p>\n<p>（2）轮廓系数</p>\n<p>结合内聚度和分离度两种因素。可以用来在相同原始数据的基础上用来评价不同算法、或者算法不同运行方式对聚类结果所产生的影响。</p>\n<p><img src=\"../img/image-20240819112914845.png\" alt=\"image-20240819112914845\"></p>\n<p>轮廓系数的范围为[−1,1]，越趋近于<code>1</code>代表内聚度和分离度都相对较优。</p>\n<p>所以可以在k-means算法开始的时候，先设置k值的范围k∈[2,n]，从而计算<code>k</code>取每一个值的轮廓系数，轮廓系数最小的那个k值就是最优的分类总数。</p>\n<p><strong>K-Means初始化优化K-Means++</strong></p>\n<p>k个初始化的质心的位置选择对最后的聚类结果和运行时间都有很大的影响，因此需要选择合适的k个质心。如果仅仅是完全随机的选择，有可能导致算法收敛很慢。K-Means++算法就是对K-Means随机初始化质心的方法的优化。</p>\n<p><img src=\"../img/image-20240819103939807.png\" alt=\"image-20240819103939807\"></p>\n<p><strong>K-Means距离计算优化elkan K-Means</strong></p>\n<p><img src=\"../img/image-20240819114731228.png\" alt=\"image-20240819114731228\" style=\"zoom:150%;\" /></p>\n<p><strong>大样本优化Mini Batch K-Means</strong></p>\n<p>传统的K-Means算法中需要计算所有样本点到所有质心的距离，计算复杂度较高。如果样本量非常大的情况下，比如数据量达到10万，特征在100以上，此时用传统K-Means算法非常耗时。因此有了一种分批处理的改进算法Mini Batch K-Means。</p>\n<p>Mini Batch K-Means算法是K-Means算法的变种，采用小批量的数据子集减小计算时间，同时仍试图优化目标函数，这里所谓的小批量是指每次训练算法时所随机抽取的数据子集，采用这些随机产生的子集进行训练算法，大大减小了计算时间，与其他算法相比，减少了k-均值的收敛时间，小批量k-均值产生的结果，一般只略差于标准算法。</p>\n<p>该算法的迭代步骤有两步：</p>\n<ul>\n<li>从数据集中随机抽取一些数据形成小批量，把他们分配给最近的质心</li>\n<li>更新质心<br>与K均值算法相比，数据的更新是在每一个小的样本集上。对于每一个小批量，通过计算平均值得到更新质心，并把小批量里的数据分配给该质心，随着迭代次数的增加，这些质心的变化是逐渐减小的，直到质心稳定或者达到指定的迭代次数，停止计算。<br>Mini Batch K-Means比K-Means有更快的 收敛速度，但同时也降低了聚类的效果，但是在实际项目中却表现得不明显，有差异的基本都是聚类边界上的点。</li>\n</ul>\n<p>　<strong>K-Means的主要优点有：</strong></p>\n<p>　　　　1）原理比较简单，实现也是很容易，收敛速度快。</p>\n<p>　　　　2）聚类效果较优。</p>\n<p>　　　　3）算法的可解释度比较强。</p>\n<p>　　　　4）主要需要调参的参数仅仅是簇数k。</p>\n<p>　<strong>K-Means的主要缺点有：</strong></p>\n<p>　　　　1）K值的选取不好把握</p>\n<p>　　　　2）对于不是凸的数据集比较难收敛</p>\n<p>　　　　3）如果各隐含类别的数据不平衡，比如各隐含类别的数据量严重失衡，或者各隐含类别的方差不同，则          聚类效果不佳。</p>\n<p>　　　　4） 采用迭代方法，得到的结果只是局部最优。</p>\n<p>　　　　5） 对噪音和异常点比较的敏感。</p>\n<h2 id=\"10-2-异常检测（anomaly-detection）\"><a href=\"#10-2-异常检测（anomaly-detection）\" class=\"headerlink\" title=\"10.2 异常检测（anomaly detection）\"></a>10.2 异常检测（anomaly detection）</h2><p>异常检测是通过数据挖掘方法发现与数据集分布不一致的异常数据，也被称为离群点、异常值检测等等。在异常检测中，我们通常处理的是未标记的数据，即没有明确的标签指示哪些样本是异常的。相反，算法需要根据数据本身的特征来确定异常。这使得异常检测成为一项挑战，因为异常通常是稀有事件，不易获取大量标记的异常数据以进行训练，我们可以将其视为一种“半监督”学习，因为我们通常有一些正常样本，但没有足够的异常样本。这种情况下，我们可以利用正常样本来构建模型，然后将其应用于整个数据集以检测异常。</p>\n<p>异常检测算法适用的场景特点有：（1）无标签或者类别极不均衡；（2）异常数据跟样本中大多数数据的差异性较大；（3）异常数据在总体数据样本中所占的比例很低。</p>\n<p><a href=\"https://www.cnblogs.com/FavoriteStar/p/16994931.html\">【机器学习】李宏毅——Anomaly Detection（异常检测） - FavoriteStar - 博客园 (cnblogs.com)</a></p>\n<p><a href=\"https://www.cnblogs.com/haohai9309/p/18180010\">异常检测(Anomaly Detection)方法与Python实现 - 郝hai - 博客园 (cnblogs.com)</a></p>\n<p><a href=\"https://blog.csdn.net/m0_59596937/article/details/128877355?ops_request_misc=%7B%22request%5Fid%22%3A%22172403972916800182147843%22%2C%22scm%22%3A%2220140713.130102334..%22%7D&amp;request_id=172403972916800182147843&amp;biz_id=0&amp;utm_medium=distribute.pc_search_result.none-task-blog-2~all~top_positive~default-1-128877355-null-null.142^v100^pc_search_result_base2&amp;utm_term=异常检测&amp;spm=1018.2226.3001.4187\">一文详解8种异常检测算法（附Python代码）-CSDN博客</a></p>\n<p><a href=\"https://blog.csdn.net/xhtchina/article/details/125121203?ops_request_misc=&amp;request_id=&amp;biz_id=102&amp;utm_term=异常检测&amp;utm_medium=distribute.pc_search_result.none-task-blog-2~all~sobaiduweb~default-4-125121203.142^v100^pc_search_result_base2&amp;spm=1018.2226.3001.4187\">异常检测方法总结_s.quantile(.25), s.quantile(.75)-CSDN博客</a></p>\n<h2 id=\"10-3-推荐系统-Recommender-System\"><a href=\"#10-3-推荐系统-Recommender-System\" class=\"headerlink\" title=\"10.3 推荐系统(Recommender System)\"></a>10.3 推荐系统(Recommender System)</h2><p><strong>（1）推荐系统的定义</strong><br>推荐系统（Recommendation System, RS）是一种自动联系用户和物品的工具，它能够帮助用户在信息过载的环境中发现令他们感兴趣的信息。它通常由前台的展示页面、后台的日志系统、推荐算法系统三个部分组成。</p>\n<h3 id=\"10-3-1协同过滤（Collaborative-Filtering）\"><a href=\"#10-3-1协同过滤（Collaborative-Filtering）\" class=\"headerlink\" title=\"10.3.1协同过滤（Collaborative Filtering）\"></a>10.3.1协同过滤（Collaborative Filtering）</h3><p><a href=\"https://blog.csdn.net/m0_37739193/article/details/119388606?ops_request_misc=%7B%22request%5Fid%22%3A%22172404698016800178541405%22%2C%22scm%22%3A%2220140713.130102334..%22%7D&amp;request_id=172404698016800178541405&amp;biz_id=0&amp;utm_medium=distribute.pc_search_result.none-task-blog-2~all~sobaiduend~default-4-119388606-null-null.142^v100^pc_search_result_base2&amp;utm_term=协同过滤&amp;spm=1018.2226.3001.4187\">算法篇—协同过滤_协同过滤算法-CSDN博客</a></p>\n<p><a href=\"https://blog.csdn.net/qq_45301231/article/details/122089100?ops_request_misc=%7B%22request%5Fid%22%3A%22172404698016800178541405%22%2C%22scm%22%3A%2220140713.130102334..%22%7D&amp;request_id=172404698016800178541405&amp;biz_id=0&amp;utm_medium=distribute.pc_search_result.none-task-blog-2~all~top_positive~default-1-122089100-null-null.142^v100^pc_search_result_base2&amp;utm_term=协同过滤&amp;spm=1018.2226.3001.4187\">推荐系统之协同过滤算法_协同过滤推荐算法-CSDN博客</a></p>\n<p><a href=\"https://blog.csdn.net/baishuiniyaonulia/article/details/111030265?ops_request_misc=%7B%22request%5Fid%22%3A%22172404695516800178573677%22%2C%22scm%22%3A%2220140713.130102334..%22%7D&amp;request_id=172404695516800178573677&amp;biz_id=0&amp;utm_medium=distribute.pc_search_result.none-task-blog-2~all~top_positive~default-1-111030265-null-null.142^v100^pc_search_result_base2&amp;utm_term=推荐系统&amp;spm=1018.2226.3001.4187\">一文入门推荐系统——推荐系统实践读书笔记_推荐系统入门教程-CSDN博客</a></p>\n<h3 id=\"10-3-2-PCA\"><a href=\"#10-3-2-PCA\" class=\"headerlink\" title=\"10.3.2 PCA\"></a>10.3.2 PCA</h3><p><a href=\"https://blog.csdn.net/weixin_45142381/article/details/127150708?ops_request_misc=%7B%22request%5Fid%22%3A%22172405641016800213091544%22%2C%22scm%22%3A%2220140713.130102334..%22%7D&amp;request_id=172405641016800213091544&amp;biz_id=0&amp;utm_medium=distribute.pc_search_result.none-task-blog-2~all~top_positive~default-1-127150708-null-null.142^v100^pc_search_result_base2&amp;utm_term=pca&amp;spm=1018.2226.3001.4187\">主成分分析法（PCA）-CSDN博客</a></p>\n<p><a href=\"https://blog.csdn.net/baishuiniyaonulia/article/details/111030265?ops_request_misc=%7B%22request%5Fid%22%3A%22172404695516800178573677%22%2C%22scm%22%3A%2220140713.130102334..%22%7D&amp;request_id=172404695516800178573677&amp;biz_id=0&amp;utm_medium=distribute.pc_search_result.none-task-blog-2~all~top_positive~default-1-111030265-null-null.142^v100^pc_search_result_base2&amp;utm_term=推荐系统&amp;spm=1018.2226.3001.4187\">一文入门推荐系统——推荐系统实践读书笔记_推荐系统入门教程-CSDN博客</a></p>\n<p><a href=\"https://blog.csdn.net/ZuHaohua/article/details/131187491?ops_request_misc=%7B%22request%5Fid%22%3A%22172405641016800213091544%22%2C%22scm%22%3A%2220140713.130102334..%22%7D&amp;request_id=172405641016800213091544&amp;biz_id=0&amp;utm_medium=distribute.pc_search_result.none-task-blog-2~all~top_click~default-2-131187491-null-null.142^v100^pc_search_result_base2&amp;utm_term=pca&amp;spm=1018.2226.3001.4187\">降维算法之PCA：从原理到应用，8000多字，助你彻底理解！_pca降维-CSDN博客</a></p>\n<p><a href=\"https://cloud.tencent.com/developer/article/1813350\">一文读懂PCA分析 （原理、算法、解释和可视化）-腾讯云开发者社区-腾讯云 (tencent.com)</a></p>\n","feature":true,"text":"一、绪论1.1 Machine Learning definitionArthur Samuel (1959). Machine Learning: “Fiel...","permalink":"/post/机器学习初级","photos":[],"count_time":{"symbolsCount":"45k","symbolsTime":"41 mins."},"categories":[],"tags":[{"name":"Deep Learning","slug":"Deep-Learning","count":1,"path":"api/tags/Deep-Learning.json"}],"toc":"<ol class=\"toc\"><li class=\"toc-item toc-level-1\"><a class=\"toc-link\" href=\"#%E4%B8%80%E3%80%81%E7%BB%AA%E8%AE%BA\"><span class=\"toc-text\">一、绪论</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#1-1-Machine-Learning-definition\"><span class=\"toc-text\">1.1 Machine Learning definition</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#%E6%A0%B7%E6%9C%AC-sample-%E3%80%81%E7%89%B9%E5%BE%81-feature-%E3%80%81%E6%A0%87%E7%AD%BE-label\"><span class=\"toc-text\">样本(sample)、特征(feature)、标签(label)</span></a></li></ol></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#1-2-Supervised-Learning\"><span class=\"toc-text\">1.2 Supervised Learning</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#1-3-Unsupervised-Learning\"><span class=\"toc-text\">1.3 Unsupervised Learning</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#1-4-Semi-supervised-Learning\"><span class=\"toc-text\">1.4 Semi-supervised Learning</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#1-5-Reinforcement-Learning\"><span class=\"toc-text\">1.5 Reinforcement Learning</span></a></li></ol></li><li class=\"toc-item toc-level-1\"><a class=\"toc-link\" href=\"#%E4%BA%8C%E3%80%81%E5%8D%95%E5%8F%98%E9%87%8F%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92\"><span class=\"toc-text\">二、单变量线性回归</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#2-1-%E5%8F%82%E6%95%B0-Parameter\"><span class=\"toc-text\">2.1 参数(Parameter)</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#2-2-%E8%AE%AD%E7%BB%83%E9%9B%86%EF%BC%88train-set%EF%BC%89%E3%80%81%E9%AA%8C%E8%AF%81%E9%9B%86%EF%BC%88validation-set%EF%BC%89%E3%80%81%E9%AA%8C%E8%AF%81%E9%9B%86%EF%BC%88validation-set%EF%BC%89\"><span class=\"toc-text\">2.2 训练集（train set）、验证集（validation set）、验证集（validation set）</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#2-3-%E4%BA%A4%E5%8F%89%E9%AA%8C%E8%AF%81%EF%BC%88Cross-Validation%EF%BC%89\"><span class=\"toc-text\">2.3 交叉验证（Cross-Validation）</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#2-4-%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0-%E4%BB%A3%E4%BB%B7%E5%87%BD%E6%95%B0%EF%BC%88Loss-Cost-Function%EF%BC%89\"><span class=\"toc-text\">2.4 损失函数&#x2F;代价函数（Loss&#x2F;Cost Function）</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#2-4-1%E5%9B%9E%E5%BD%92%E6%8D%9F%E5%A4%B1-Regression-Loss\"><span class=\"toc-text\">2.4.1回归损失(Regression Loss)</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-4\"><a class=\"toc-link\" href=\"#L1-Loss\"><span class=\"toc-text\">L1 Loss</span></a></li><li class=\"toc-item toc-level-4\"><a class=\"toc-link\" href=\"#L2-Loss\"><span class=\"toc-text\">L2 Loss</span></a></li></ol></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#2-4-2%E5%88%86%E7%B1%BB%E6%8D%9F%E5%A4%B1-Classification-Loss\"><span class=\"toc-text\">2.4.2分类损失(Classification Loss)</span></a></li></ol></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#2-5-%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D-Gradient-Descent\"><span class=\"toc-text\">2.5 梯度下降(Gradient Descent)</span></a></li></ol></li><li class=\"toc-item toc-level-1\"><a class=\"toc-link\" href=\"#%E4%B8%89%E3%80%81%E5%A4%9A%E5%8F%98%E9%87%8F%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92-Linear-Regression-with-Multiple-Variables\"><span class=\"toc-text\">三、多变量线性回归(Linear Regression with Multiple Variables)</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#3-1-%E5%90%91%E9%87%8F%E5%8C%96%EF%BC%88vectorization%EF%BC%89\"><span class=\"toc-text\">3.1 向量化（vectorization）</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#3-2-%E7%94%A8%E4%BA%8E%E5%A4%9A%E5%85%83%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%E7%9A%84%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E6%B3%95\"><span class=\"toc-text\">3.2 用于多元线性回归的梯度下降法</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#3-3-%E7%89%B9%E5%BE%81%E7%BC%A9%E6%94%BE%EF%BC%88Feature-Scaling%EF%BC%89\"><span class=\"toc-text\">3.3 特征缩放（Feature Scaling）</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#%E7%89%B9%E5%BE%81%E5%90%91%E9%87%8F%EF%BC%88Eigenvector%EF%BC%89\"><span class=\"toc-text\">特征向量（Eigenvector）</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#%E7%89%B9%E5%BE%81%E7%BC%A9%E6%94%BE%E6%84%8F%E4%B9%89\"><span class=\"toc-text\">特征缩放意义</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#%E6%A0%87%E5%87%86%E5%8C%96%EF%BC%88Standardization-Z-Score-Normalization%EF%BC%89\"><span class=\"toc-text\">标准化（Standardization&#x2F;Z-Score Normalization）</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#%E5%BD%92%E4%B8%80%E5%8C%96%EF%BC%88Rescaling-Normalization%EF%BC%89\"><span class=\"toc-text\">归一化（Rescaling&#x2F;Normalization）</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#%E5%9D%87%E5%80%BC%E5%BD%92%E4%B8%80%E5%8C%96-Mean-Normalization\"><span class=\"toc-text\">均值归一化(Mean Normalization)</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#%E5%B7%AE%E5%BC%82\"><span class=\"toc-text\">差异</span></a></li></ol></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#3-4-%E5%A4%9A%E9%A1%B9%E5%BC%8F%E5%9B%9E%E5%BD%92\"><span class=\"toc-text\">3.4 多项式回归</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#3-5-%E6%AD%A3%E8%A7%84%E6%96%B9%E7%A8%8B\"><span class=\"toc-text\">3.5 正规方程</span></a></li></ol></li><li class=\"toc-item toc-level-1\"><a class=\"toc-link\" href=\"#%E5%9B%9B%E3%80%81%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92%EF%BC%88Logistic-Regression%EF%BC%89\"><span class=\"toc-text\">四、逻辑回归（Logistic Regression）</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#4-1-%E7%90%86%E8%AE%BA%E6%8E%A8%E5%AF%BC\"><span class=\"toc-text\">4.1 理论推导</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#4-2-%E5%86%B3%E7%AD%96%E8%BE%B9%E7%95%8C%EF%BC%88Decision-Boundary%EF%BC%89\"><span class=\"toc-text\">4.2 决策边界（Decision Boundary）</span></a></li></ol></li><li class=\"toc-item toc-level-1\"><a class=\"toc-link\" href=\"#%E4%BA%94%E3%80%81%E6%AD%A3%E5%88%99%E5%8C%96%EF%BC%88Regularization%EF%BC%89\"><span class=\"toc-text\">五、正则化（Regularization）</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#5-1-%E8%BF%87%E6%8B%9F%E5%90%88%EF%BC%88overfitting%EF%BC%89%E3%80%81%E6%AC%A0%E6%8B%9F%E5%90%88%EF%BC%88underfitting%EF%BC%89\"><span class=\"toc-text\">5.1 过拟合（overfitting）、欠拟合（underfitting）</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#5-2-%E6%AD%A3%E5%88%99%E5%8C%96%E6%96%B9%E6%B3%95\"><span class=\"toc-text\">5.2 正则化方法</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#5-2-1-L1-%E6%AD%A3%E5%88%99%E5%8C%96\"><span class=\"toc-text\">5.2.1 L1 正则化</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#5-2-2-L2-%E6%AD%A3%E5%88%99%E5%8C%96\"><span class=\"toc-text\">5.2.2 L2 正则化</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#5-2-3-Dropout\"><span class=\"toc-text\">5.2.3 Dropout</span></a></li></ol></li></ol></li><li class=\"toc-item toc-level-1\"><a class=\"toc-link\" href=\"#%E5%85%AD%E3%80%81%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%EF%BC%88Neural-Network%EF%BC%89\"><span class=\"toc-text\">六、神经网络（Neural Network）</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#6-1-%E5%89%8D%E8%A8%80\"><span class=\"toc-text\">6.1 前言</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#6-2-%E5%8D%95%E5%B1%82%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%EF%BC%88%E6%84%9F%E7%9F%A5%E5%99%A8-Perception%EF%BC%89\"><span class=\"toc-text\">6.2 单层神经网络（感知器 Perception）</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#6-3-%E4%B8%A4%E5%B1%82%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%EF%BC%88%E5%A4%9A%E5%B1%82%E6%84%9F%E7%9F%A5%E5%99%A8MLP-Multilayer-Perceptron%EF%BC%89\"><span class=\"toc-text\">6.3 两层神经网络（多层感知器MLP Multilayer Perceptron）</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#6-4-%E6%99%AE%E9%80%9A%E5%A4%9A%E5%B1%82%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C\"><span class=\"toc-text\">6.4 普通多层神经网络</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#6-5-%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0%EF%BC%88Activation-Function%EF%BC%89\"><span class=\"toc-text\">6.5 激活函数（Activation Function）</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#6-6-%E4%BB%A3%E4%BB%B7%E5%87%BD%E6%95%B0\"><span class=\"toc-text\">6.6 代价函数</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#6-6-1-%E4%BA%A4%E5%8F%89%E7%86%B5%E4%BB%A3%E4%BB%B7%E5%87%BD%E6%95%B0%EF%BC%88Cross-entropy-Loss-Function%EF%BC%89\"><span class=\"toc-text\">6.6.1 交叉熵代价函数（Cross-entropy Loss Function）</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#6-6-2-%E4%BA%A4%E5%8F%89%E7%86%B5%E4%BB%A3%E4%BB%B7%E5%87%BD%E6%95%B0-softmax%E5%87%BD%E6%95%B0\"><span class=\"toc-text\">6.6.2 交叉熵代价函数+ softmax函数</span></a></li></ol></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#6-7-%E5%89%8D%E5%90%91%E4%BC%A0%E6%92%AD%EF%BC%88Forward-Propagation%EF%BC%89%E4%B8%8E%E5%8F%8D%E5%90%91%E4%BC%A0%E6%92%AD%EF%BC%88Back-Propagation%EF%BC%8CBP%EF%BC%89\"><span class=\"toc-text\">6.7 前向传播（Forward Propagation）与反向传播（Back Propagation，BP）</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#6-7-1-BP%E7%AE%97%E6%B3%95%E7%9A%84%E6%8E%A8%E5%AF%BC\"><span class=\"toc-text\">6.7.1 BP算法的推导</span></a></li></ol></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#6-8-%E7%8B%AC%E7%83%AD%E7%BC%96%E7%A0%81%EF%BC%88One-Hot-Encoding%EF%BC%89\"><span class=\"toc-text\">6.8 独热编码（One-Hot Encoding）</span></a></li></ol></li><li class=\"toc-item toc-level-1\"><a class=\"toc-link\" href=\"#%E4%B8%83%E3%80%81%E8%AF%AF%E5%B7%AE%E5%88%86%E6%9E%90%E4%B8%8E%E5%81%8F%E6%96%9C%E7%B1%BB%E7%9A%84%E8%AF%AF%E5%B7%AE%E5%BA%A6%E9%87%8F%EF%BC%88Error-Analysis-and-Error-Metrics-for-Skewed-Classes%EF%BC%89\"><span class=\"toc-text\">七、误差分析与偏斜类的误差度量（Error Analysis and Error Metrics for Skewed Classes）</span></a></li><li class=\"toc-item toc-level-1\"><a class=\"toc-link\" href=\"#%E5%85%AB%E3%80%81%E5%86%B3%E7%AD%96%E6%A0%91%EF%BC%88Decision-Tree%EF%BC%89\"><span class=\"toc-text\">八、决策树（Decision Tree）</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#8-1-%E7%86%B5\"><span class=\"toc-text\">8.1 熵</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#8-2-%E5%86%B3%E7%AD%96%E6%A0%91%E7%9A%84%E5%88%92%E5%88%86%E9%80%89%E6%8B%A9\"><span class=\"toc-text\">8.2 决策树的划分选择</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#%E4%BF%A1%E6%81%AF%E5%A2%9E%E7%9B%8A%EF%BC%88ID3%E5%86%B3%E7%AD%96%E6%A0%91%EF%BC%89\"><span class=\"toc-text\">信息增益（ID3决策树）</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#%E4%BF%A1%E6%81%AF%E5%A2%9E%E7%9B%8A%E7%8E%87%EF%BC%88C4-5%E5%86%B3%E7%AD%96%E6%A0%91%EF%BC%89\"><span class=\"toc-text\">信息增益率（C4.5决策树）</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#%E5%9F%BA%E5%B0%BC%E6%8C%87%E6%95%B0%EF%BC%88CART%E5%86%B3%E7%AD%96%E6%A0%91%EF%BC%89\"><span class=\"toc-text\">基尼指数（CART决策树）</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#%E4%B8%89%E7%A7%8D%E7%AE%97%E6%B3%95%E7%9A%84%E5%AF%B9%E6%AF%94\"><span class=\"toc-text\">三种算法的对比</span></a></li></ol></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#8-3-%E5%89%AA%E6%9E%9D%E5%A4%84%E7%90%86\"><span class=\"toc-text\">8.3 剪枝处理</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#8-4-%E8%BF%9E%E7%BB%AD%E4%B8%8E%E7%BC%BA%E5%A4%B1%E5%80%BC\"><span class=\"toc-text\">8.4 连续与缺失值</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#8-5-%E5%9B%9E%E5%BD%92%E6%A0%91%EF%BC%88regression-tree%EF%BC%89\"><span class=\"toc-text\">8.5 回归树（regression tree）</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#8-6-%E9%9A%8F%E6%9C%BA%E6%A3%AE%E6%9E%97%EF%BC%88Random-Forest%EF%BC%8CRF%EF%BC%89\"><span class=\"toc-text\">8.6 随机森林（Random Forest，RF）</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#8-6-1-%E8%BD%AC%E6%8D%A2%E5%99%A8%EF%BC%88transformer%EF%BC%89%E5%92%8C%E4%BC%B0%E8%AE%A1%E5%99%A8%EF%BC%88estimator%EF%BC%89\"><span class=\"toc-text\">8.6.1 转换器（transformer）和估计器（estimator）</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#8-6-2-%E9%9B%86%E6%88%90%E5%AD%A6%E4%B9%A0\"><span class=\"toc-text\">8.6.2 集成学习</span></a></li></ol></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#8-7-XGBoost%EF%BC%88eXtreme-Gradient-Boosting%EF%BC%89\"><span class=\"toc-text\">8.7 XGBoost（eXtreme Gradient Boosting）</span></a></li></ol></li><li class=\"toc-item toc-level-1\"><a class=\"toc-link\" href=\"#%E4%B9%9D%E3%80%81%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA%EF%BC%88SVM%EF%BC%8Csupport-vector-machines%EF%BC%89\"><span class=\"toc-text\">九、支持向量机（SVM，support vector machines）</span></a></li><li class=\"toc-item toc-level-1\"><a class=\"toc-link\" href=\"#%E5%8D%81%E3%80%81%E6%97%A0%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0\"><span class=\"toc-text\">十、无监督学习</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#10-1-k-means%E8%81%9A%E7%B1%BB%E7%AE%97%E6%B3%95-K-means-clustering\"><span class=\"toc-text\">10.1 k-means聚类算法(K-means clustering)</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#10-2-%E5%BC%82%E5%B8%B8%E6%A3%80%E6%B5%8B%EF%BC%88anomaly-detection%EF%BC%89\"><span class=\"toc-text\">10.2 异常检测（anomaly detection）</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#10-3-%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F-Recommender-System\"><span class=\"toc-text\">10.3 推荐系统(Recommender System)</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#10-3-1%E5%8D%8F%E5%90%8C%E8%BF%87%E6%BB%A4%EF%BC%88Collaborative-Filtering%EF%BC%89\"><span class=\"toc-text\">10.3.1协同过滤（Collaborative Filtering）</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#10-3-2-PCA\"><span class=\"toc-text\">10.3.2 PCA</span></a></li></ol></li></ol></li></ol>","author":{"name":"Gueason","slug":"blog-author","avatar":"https://pic.quanjing.com/60/2a/QJ6771797507.jpg@!350h","link":"/","description":"小白，在成为“牛码”的路上","socials":{"github":"","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"","zhihu":"","csdn":"","juejin":"","customs":{}}},"mapped":true,"hidden":false,"prev_post":{},"next_post":{"title":"Linux操作系统（搬运）","uid":"aa511ac4879771de2733384acfc7e52f","slug":"Linux操作系统（搬运）","date":"2024-07-01T00:00:00.000Z","updated":"2024-08-19T14:25:12.561Z","comments":true,"path":"api/articles/Linux操作系统（搬运）.json","keywords":null,"cover":[],"text":"Linux操作系统一、简史UNIX1970年，美国贝尔实验室的 Ken Thompson，以 BCPL语言 为基础，设计出很简单且很接近硬件的 B语言（取BCP...","permalink":"/post/Linux操作系统（搬运）","photos":[],"count_time":{"symbolsCount":"134k","symbolsTime":"2:01"},"categories":[],"tags":[{"name":"技术栈","slug":"技术栈","count":1,"path":"api/tags/技术栈.json"}],"author":{"name":"Gueason","slug":"blog-author","avatar":"https://pic.quanjing.com/60/2a/QJ6771797507.jpg@!350h","link":"/","description":"小白，在成为“牛码”的路上","socials":{"github":"","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"","zhihu":"","csdn":"","juejin":"","customs":{}}},"feature":true}}